{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "repository = 'evaluating_factuality_word_definitions'\n",
    "\n",
    "%cd /content/drive/My Drive/{repository}"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install datasets\n",
    "!pip install peft\n",
    "!pip install rank_bm25"
   ],
   "id": "2ff5f159060ac265"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:53:43.499909Z",
     "start_time": "2024-05-14T13:53:30.664694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "from dataset.def_dataset import DefinitionDataset, Fact\n",
    "from config import DB_URL\n",
    "from transformers import AutoTokenizer\n",
    "from models.evidence_selection_model import EvidenceSelectionModel\n",
    "from peft import AutoPeftModelForFeatureExtraction\n",
    "import torch\n",
    "from fever_scorer import fever_score\n",
    "from pipeline.pipeline import TestPipeline\n",
    "from pipeline.pipeline import WikiPipeline\n",
    "from utils import convert_document_id_to_word\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ],
   "id": "e403ceab1727dd57",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:53:43.626858Z",
     "start_time": "2024-05-14T13:53:43.502495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_query = \"\"\"\n",
    "select dd.id, docs.document_id, docs.text, dd.claim, dd.label, group_concat(dd.evidence_sentence_id, ';') as evidence_lines\n",
    "from def_dataset dd\n",
    "    join documents docs on docs.document_id = dd.evidence_wiki_url\n",
    "    -- join atomic_facts af on af.claim_id = dd.id\n",
    "where set_type='{set_type}' -- and length(claim) < 50 and length(docs.text) < 400\n",
    "group by dd.id, evidence_annotation_id, evidence_wiki_url\n",
    "limit 40\n",
    "\"\"\"\n",
    "\n",
    "raw_dataset = Dataset.from_sql(dataset_query.format(set_type='dev'), con=DB_URL)\n",
    "dataset = DefinitionDataset(raw_dataset, tokenizer=None, model='claim_verification')"
   ],
   "id": "8b30c3030dc3b7a4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:53:47.906748Z",
     "start_time": "2024-05-14T13:53:43.629848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#model_name = 'google/bigbird-roberta-large'\n",
    "#model = AutoPeftModelForFeatureExtraction.from_pretrained('selection_model_intermediate_04-30_09-40')\n",
    "\n",
    "selection_model_tokenizer = AutoTokenizer.from_pretrained('Snowflake/snowflake-arctic-embed-m-long')\n",
    "model = AutoModel.from_pretrained('Snowflake/snowflake-arctic-embed-m-long', trust_remote_code=True, add_pooling_layer=False, safe_serialization=True)\n",
    "selection_model = EvidenceSelectionModel(model).to(device)\n",
    "#selection_model_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# still using base\n",
    "verification_model=None\n",
    "verification_model_tokenizer=None"
   ],
   "id": "75e11a7abea5c82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:54:12.384312Z",
     "start_time": "2024-05-14T13:53:47.908895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import build_fever_instance\n",
    "\n",
    "test_pipeline = TestPipeline(selection_model=selection_model,selection_model_tokenizer=selection_model_tokenizer)\n",
    "\n",
    "#test_pipeline = TestPipeline()\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "fever_instances = []\n",
    "for entry in tqdm(dataset):\n",
    "    output = test_pipeline.verify(entry['document_id'], entry['claim'])\n",
    "    pr_labels.extend([fact.to_factuality() for fact in output['factualities']])\n",
    "    gt_labels += [Fact[entry['label']].to_factuality()] * len(output['factualities'])\n",
    "\n",
    "    evidence = entry['evidence_lines'].split(';')\n",
    "    predicted_label = output.get('factualities')[0]  # TODO add atomic fact support\n",
    "    predicted_evidence = output.get('evidences')\n",
    "    fever_instance = build_fever_instance(entry['label'], evidence, entry['document_id'], predicted_label, predicted_evidence)\n",
    "    fever_instances.append(fever_instance)\n",
    "\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0))\n",
    "strict_score, label_accuracy, precision, recall, f1 = fever_score(fever_instances)\n",
    "\n",
    "print(strict_score)  \n",
    "print(label_accuracy) \n",
    "print(precision)  # TP / TP + FP not too important, rather at least one TP than none\n",
    "print(recall)     # more important\n",
    "print(f1)"
   ],
   "id": "d507832f116241d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:22<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.90      0.56      0.69        16\n",
      "           1       0.84      0.93      0.88        28\n",
      "\n",
      "    accuracy                           0.80        44\n",
      "   macro avg       0.58      0.50      0.52        44\n",
      "weighted avg       0.86      0.80      0.81        44\n",
      "\n",
      "0.7777777777777778\n",
      "0.8055555555555556\n",
      "0.5324074074074074\n",
      "0.9444444444444444\n",
      "0.6809474050853361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:49:54.106258Z",
     "start_time": "2024-05-09T15:49:54.098048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print([int(label) for label in pr_labels])\n",
    "print(gt_labels)"
   ],
   "id": "c3ca0dd319c76ad5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 0, 1, -1, 1, 0, -1, -1, -1, -1]\n",
      "[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:54:16.803246Z",
     "start_time": "2024-05-14T13:54:16.797040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strict_score, label_accuracy, precision, recall, f1 = fever_score(fever_instances, use_gold_labels=True)\n",
    "print(strict_score)  \n",
    "print(label_accuracy) \n",
    "print(precision)  \n",
    "print(recall) \n",
    "print(f1)"
   ],
   "id": "5404d7dfa053985e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "1.0\n",
      "0.5324074074074074\n",
      "0.9444444444444444\n",
      "0.6809474050853361\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T13:19:23.196315Z",
     "start_time": "2024-05-13T13:19:16.424386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = WikiPipeline(selection_model=selection_model, selection_model_tokenizer=selection_model_tokenizer)\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = convert_document_id_to_word(entry['document_id'])\n",
    "    \n",
    "    factuality = pipeline.verify(word, entry['claim'])\n",
    "    pr_labels.extend([fact.to_factuality() for fact in factuality])\n",
    "    gt_labels += [Fact[entry['label']].to_factuality()] * len(factuality)\n",
    "\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0))\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0))\n",
    "strict_score, label_accuracy, precision, recall, f1 = fever_score(fever_instances)\n",
    "\n",
    "print(strict_score)  \n",
    "print(label_accuracy) \n",
    "print(precision)  \n",
    "print(recall)  \n",
    "print(f1)"
   ],
   "id": "3e2428de6e135e4c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_factuality'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m     word \u001B[38;5;241m=\u001B[39m convert_document_id_to_word(entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocument_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      8\u001B[0m     factuality \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mverify(word, entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclaim\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 9\u001B[0m     pr_labels\u001B[38;5;241m.\u001B[39mextend([fact\u001B[38;5;241m.\u001B[39mto_factuality() \u001B[38;5;28;01mfor\u001B[39;00m fact \u001B[38;5;129;01min\u001B[39;00m factuality])\n\u001B[1;32m     10\u001B[0m     gt_labels \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [Fact[entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mto_factuality()] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(factuality)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(classification_report(gt_labels, pr_labels, zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "Cell \u001B[0;32mIn[7], line 9\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      6\u001B[0m     word \u001B[38;5;241m=\u001B[39m convert_document_id_to_word(entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocument_id\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      8\u001B[0m     factuality \u001B[38;5;241m=\u001B[39m pipeline\u001B[38;5;241m.\u001B[39mverify(word, entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclaim\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 9\u001B[0m     pr_labels\u001B[38;5;241m.\u001B[39mextend([\u001B[43mfact\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_factuality\u001B[49m() \u001B[38;5;28;01mfor\u001B[39;00m fact \u001B[38;5;129;01min\u001B[39;00m factuality])\n\u001B[1;32m     10\u001B[0m     gt_labels \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [Fact[entry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]]\u001B[38;5;241m.\u001B[39mto_factuality()] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(factuality)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(classification_report(gt_labels, pr_labels, zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'to_factuality'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print([int(label) for label in pr_labels])\n",
    "print(gt_labels)"
   ],
   "id": "7f6546c454fe6b7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
