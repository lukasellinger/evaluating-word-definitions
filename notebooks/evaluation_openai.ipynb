{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 0 Preparations\n",
    "Before starting, ensure that you have cloned the repository to your Google Drive.\n",
    "We will connect to this:"
   ],
   "id": "89efdde2f316a2ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "repository = 'evaluating_factuality_word_definitions'\n",
    "\n",
    "%cd /content/drive/My Drive/{repository}"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we install the packages and import the modules needed in this notebook:",
   "id": "6231d35ad484e964"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%capture\n",
    "!pip install datasets~=2.18.0\n",
    "!pip install openai~=1.35.10"
   ],
   "id": "96b44e8e7b8c3cb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T13:31:59.087470Z",
     "start_time": "2024-09-30T13:31:52.050243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import FACT_EVULATION_OPENAI_TOKEN, PROJECT_DIR\n",
    "from fetchers.openai import OpenAiFetcher\n",
    "from general_utils.reader import JSONLineReader\n",
    "from general_utils.utils import get_openai_prediction, parse_model_answer"
   ],
   "id": "fdbe8cbeb93713f4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1 Setup: Define Datasets\n",
    "Now we define our models and datasets we want to evaluate:"
   ],
   "id": "f06ff4f131279207"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:16:13.394269Z",
     "start_time": "2024-09-30T14:16:00.189030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Datasets with language information\n",
    "datasets = {\n",
    "    'german_dpr-claim_verification': {\n",
    "        'dataset': load_dataset('lukasellinger/german_dpr-claim_verification', split='test'),\n",
    "        'lang': 'de'\n",
    "    },\n",
    "    'german_wiktionary-claim_verification-mini': {\n",
    "        'dataset': load_dataset('lukasellinger/german_wiktionary-claim_verification-mini', split='test'),\n",
    "        'lang': 'de'\n",
    "    },\n",
    "    'squad-claim_verification': {\n",
    "        'dataset': load_dataset('lukasellinger/squad-claim_verification', split='test'),\n",
    "        'lang': 'en'\n",
    "    },\n",
    "    'shroom-claim_verification': {\n",
    "        'dataset': load_dataset('lukasellinger/shroom-claim_verification', split='test'),\n",
    "        'lang': 'en'\n",
    "    },\n",
    "    ## optional (contains 10k entries)\n",
    "    #'german_wiktionary-claim_verification-large': {\n",
    "    #    'dataset': load_dataset('lukasellinger/german_wiktionary-claim_verification-large', split='test'),\n",
    "    #    'lang': 'de'\n",
    "    #},\n",
    "    # outdated\n",
    "    #'german-claim_verification': {\n",
    "    #    'dataset': load_dataset('lukasellinger/german-claim_verification', split='test'),\n",
    "    #    'lang': 'de'\n",
    "    #},\n",
    "}"
   ],
   "id": "58d3ac7722cd6800",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:16:13.401961Z",
     "start_time": "2024-09-30T14:16:13.397612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [\n",
    "    'gpt-3.5-turbo',\n",
    "    'gpt-4o-mini',\n",
    "    'gpt-4o'\n",
    "]"
   ],
   "id": "ff15217b5457a60e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:16:13.450047Z",
     "start_time": "2024-09-30T14:16:13.404771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai_fetcher = OpenAiFetcher(api_key=FACT_EVULATION_OPENAI_TOKEN)\n",
    "fh = JSONLineReader()"
   ],
   "id": "cc825c4d6b0397ab",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:16:13.457627Z",
     "start_time": "2024-09-30T14:16:13.453698Z"
    }
   },
   "cell_type": "code",
   "source": "EVALUATION_DIR = PROJECT_DIR / 'data/evaluation'",
   "id": "efb60ae2050d9965",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:20:14.077439Z",
     "start_time": "2024-09-30T15:20:14.062885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_task(idx, model, content):\n",
    "    return {\n",
    "            \"custom_id\": f\"task-{idx}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": model,\n",
    "                \"temperature\": 0.1,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": content\n",
    "                    }\n",
    "                ],\n",
    "                \"seed\": 42,\n",
    "                \"logprobs\": True,\n",
    "                \"top_logprobs\": 5\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def create_tasks(dataset, model, file_name, prompt_func):\n",
    "    tasks = [build_task(idx, model, prompt_func(entry)) for idx, entry in enumerate(dataset)]\n",
    "    fh.write(file_name, tasks, mode='w')\n",
    "\n",
    "\n",
    "def create_long_german_prompt(entry):\n",
    "    return f'Bitte überprüfen die folgende Aussage über {entry[\"word\"]}. Aussage: {entry[\"claim\"]} Wahr oder Falsch?\\nAusgabe:'\n",
    "\n",
    "    \n",
    "def create_long_prompt(entry):\n",
    "    return create_long_prompt_from_claim(entry['word'], entry['claim'])\n",
    "\n",
    "\n",
    "def create_connected_prompt(entry):\n",
    "    return f'Please verify the following statement. Input: {entry[\"connected_claim\"]} True or False?\\nOutput:'\n",
    "\n",
    "\n",
    "def create_long_prompt_from_claim(word, claim):\n",
    "    return f'Please verify the following statement about {word}. Input: {claim} True or False?\\nOutput:'\n",
    "\n",
    "\n",
    "def create_long_translation_prompt(entry):\n",
    "    return f'Please verify the following statement about {entry[\"english_word\"]}. Input: {entry[\"english_claim\"]} True or False?\\nOutput:'\n",
    "\n",
    "\n",
    "def create_short_prompt(entry):\n",
    "    return f'Input: {entry[\"word\"]}: {entry[\"claim\"]} True or False?\\nOutput:'\n",
    "    \n",
    "    \n",
    "def process_results(file_name, dataset, translations: bool, lang='en'):\n",
    "    results = fh.read(file_name)\n",
    "    outputs, all_gt_labels, all_pr_labels, wiki_gt_labels, wiki_pr_labels = [], [], [], [], []\n",
    "\n",
    "    for res in results:\n",
    "        task_id = res['custom_id']\n",
    "        index = int(task_id.split('-')[-1])\n",
    "        entry = dataset[index]\n",
    "        claim = entry['claim']\n",
    "        word = entry['word']\n",
    "        predicted = get_openai_prediction(res['response']['body'])\n",
    "        if predicted == 'UNKNOWN':\n",
    "            txt_answer = res['response']['body']['choices'][0]['message']['content']\n",
    "            predicted = parse_model_answer(txt_answer, language=lang)\n",
    "        \n",
    "        output = {\n",
    "            'id': entry['id'],\n",
    "            'word': word,\n",
    "            'claim': claim,\n",
    "            'label': entry['label'],\n",
    "            'predicted': predicted,\n",
    "            'in_wiki': entry['in_wiki']\n",
    "        }\n",
    "        \n",
    "        if translations:\n",
    "            output['translated_word'] = entry['english_word']\n",
    "            output['translated_claim'] = entry['english_claim']\n",
    "        \n",
    "        outputs.append(output)\n",
    "        gt_label = 1 if output['label'] == 'SUPPORTED' else 0\n",
    "        pr_label = 1 if output['predicted'] == 'SUPPORTED' else 0\n",
    "        all_gt_labels.append(gt_label)\n",
    "        all_pr_labels.append(pr_label)\n",
    "        if output['in_wiki'] == 'Yes':\n",
    "            wiki_gt_labels.append(gt_label)\n",
    "            wiki_pr_labels.append(pr_label)\n",
    "        \n",
    "    report = classification_report(all_gt_labels, all_pr_labels, zero_division=0, digits=4)\n",
    "    wiki_report = classification_report(wiki_gt_labels, wiki_pr_labels, zero_division=0, digits=4)\n",
    "    print('Report all entries:')\n",
    "    print(report)\n",
    "    print('Filtered Report for entries with evidence in wikipedia:')\n",
    "    print(wiki_report)\n",
    "    return outputs"
   ],
   "id": "64c17942c1b6ff67",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 Manual Batch Fetching",
   "id": "14a65477f8c45bf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:17:34.092034Z",
     "start_time": "2024-09-30T14:17:34.088074Z"
    }
   },
   "cell_type": "code",
   "source": "batch_jobs = {}",
   "id": "f71f6b1a50ee0e88",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:22:12.701575Z",
     "start_time": "2024-09-30T14:22:11.523501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_file_name = str(EVALUATION_DIR / 'german_dpr-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-german_dpr-claim_verification-gpt-4o-mini.jsonl')\n",
    "batch_job = openai_fetcher.create_batch_job(input_file_name)\n",
    "batch_jobs[input_file_name] = batch_job"
   ],
   "id": "751caf640f37d0df",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:22:16.696182Z",
     "start_time": "2024-09-30T14:22:16.691625Z"
    }
   },
   "cell_type": "code",
   "source": "len(batch_jobs)",
   "id": "de4f41a7679be621",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:56:18.998693Z",
     "start_time": "2024-09-30T14:56:15.855190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file_name, batch_job in batch_jobs.items():\n",
    "    batch_job = openai_fetcher.get_batch_update(batch_job)\n",
    "    batch_jobs[file_name] = batch_job\n",
    "    print(file_name)\n",
    "    print(batch_job)\n",
    "    print(\"_______________\")"
   ],
   "id": "8d1713d07602d940",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/squad-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-squad-claim_verification-gpt-4o-mini.jsonl\n",
      "Batch(id='batch_66fab332d7f081908f5352b706b12879', completion_window='24h', created_at=1727705907, endpoint='/v1/chat/completions', input_file_id='file-jMqHUJ260guskRlHM4X17dMT', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706044, error_file_id=None, errors=None, expired_at=None, expires_at=1727792307, failed_at=None, finalizing_at=1727706032, in_progress_at=1727705907, metadata=None, output_file_id='file-nFVtlkaKDFh6bVzNe7bjGG6v', request_counts=BatchRequestCounts(completed=158, failed=0, total=158))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/squad-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-squad-claim_verification-gpt-4o.jsonl\n",
      "Batch(id='batch_66fab33884fc81908f4090fca29e71eb', completion_window='24h', created_at=1727705912, endpoint='/v1/chat/completions', input_file_id='file-PxfYQw3S6Vr51ehnHapaDLxZ', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706044, error_file_id=None, errors=None, expired_at=None, expires_at=1727792312, failed_at=None, finalizing_at=1727706022, in_progress_at=1727705913, metadata=None, output_file_id='file-ueI6ThYCTVZTocApNMHl4AZP', request_counts=BatchRequestCounts(completed=158, failed=0, total=158))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/squad-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-squad-claim_verification-gpt-3.5-turbo.jsonl\n",
      "Batch(id='batch_66fab3446e388190b2220ebfc808a1cb', completion_window='24h', created_at=1727705924, endpoint='/v1/chat/completions', input_file_id='file-R64AcuQIuNNaaVfQ0MtNNfOe', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706453, error_file_id=None, errors=None, expired_at=None, expires_at=1727792324, failed_at=None, finalizing_at=1727706440, in_progress_at=1727705925, metadata=None, output_file_id='file-kJxRT9kDkXy3lVvHCmbrJgTO', request_counts=BatchRequestCounts(completed=158, failed=0, total=158))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/shroom-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-shroom-claim_verification-gpt-3.5-turbo.jsonl\n",
      "Batch(id='batch_66fab36259f48190865b4597a5da21a7', completion_window='24h', created_at=1727705954, endpoint='/v1/chat/completions', input_file_id='file-ZLUJrxgujPPlJc46A09wzJ2J', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706507, error_file_id=None, errors=None, expired_at=None, expires_at=1727792354, failed_at=None, finalizing_at=1727706463, in_progress_at=1727706015, metadata=None, output_file_id='file-VqdRJUtbKn58Mjl6nt2k6nN2', request_counts=BatchRequestCounts(completed=563, failed=0, total=563))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/shroom-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-shroom-claim_verification-gpt-4o.jsonl\n",
      "Batch(id='batch_66fab367c82c8190a8a68ff8c3dc1e44', completion_window='24h', created_at=1727705959, endpoint='/v1/chat/completions', input_file_id='file-CR3Vrq6GvORgzf2l8ikd0zod', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706306, error_file_id=None, errors=None, expired_at=None, expires_at=1727792359, failed_at=None, finalizing_at=1727706247, in_progress_at=1727705961, metadata=None, output_file_id='file-W5wmcZulLSq0QrYJlE8l7a0f', request_counts=BatchRequestCounts(completed=563, failed=0, total=563))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/shroom-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-shroom-claim_verification-gpt-4o-mini.jsonl\n",
      "Batch(id='batch_66fab36d741c8190801a37e1c8e56761', completion_window='24h', created_at=1727705965, endpoint='/v1/chat/completions', input_file_id='file-Qsm7icJdzgtR3SD5X2h4778r', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706872, error_file_id=None, errors=None, expired_at=None, expires_at=1727792365, failed_at=None, finalizing_at=1727706822, in_progress_at=1727705966, metadata=None, output_file_id='file-9a2D1wKdowGkyCXx1K3L3e1z', request_counts=BatchRequestCounts(completed=563, failed=0, total=563))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/german_wiktionary-claim_verification-mini/zero_shot/input/input_zero_shot_connected_prompt-german_wiktionary-claim_verification-mini-gpt-4o-mini.jsonl\n",
      "Batch(id='batch_66fab3cbe1688190808390fae6b20296', completion_window='24h', created_at=1727706060, endpoint='/v1/chat/completions', input_file_id='file-Z0fTNBbVibXHMNkcMfq0k1W1', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727707966, error_file_id=None, errors=None, expired_at=None, expires_at=1727792460, failed_at=None, finalizing_at=1727707946, in_progress_at=1727706060, metadata=None, output_file_id='file-XMq8l7ul8fEIywIozUBDCWpj', request_counts=BatchRequestCounts(completed=200, failed=0, total=200))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/german_wiktionary-claim_verification-mini/zero_shot/input/input_zero_shot_connected_prompt-german_wiktionary-claim_verification-mini-gpt-4o.jsonl\n",
      "Batch(id='batch_66fab3d370a08190b437b4391d9d6d9a', completion_window='24h', created_at=1727706067, endpoint='/v1/chat/completions', input_file_id='file-gsQDyjujjx8Cx2sc0i0oQEUc', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706192, error_file_id=None, errors=None, expired_at=None, expires_at=1727792467, failed_at=None, finalizing_at=1727706178, in_progress_at=1727706068, metadata=None, output_file_id='file-J5rBZsn7uKFLzYryPp4ylMIC', request_counts=BatchRequestCounts(completed=200, failed=0, total=200))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/german_wiktionary-claim_verification-mini/zero_shot/input/input_zero_shot_connected_prompt-german_wiktionary-claim_verification-mini-gpt-3.5-turbo.jsonl\n",
      "Batch(id='batch_66fab3db7b708190807f4a49d6ba7244', completion_window='24h', created_at=1727706075, endpoint='/v1/chat/completions', input_file_id='file-EeD4Dyu1Mcoijjj4rTHX0oa2', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706466, error_file_id=None, errors=None, expired_at=None, expires_at=1727792475, failed_at=None, finalizing_at=1727706452, in_progress_at=1727706076, metadata=None, output_file_id='file-dchCPszMiqqBpaoCsrQyT2um', request_counts=BatchRequestCounts(completed=200, failed=0, total=200))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/german_dpr-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-german_dpr-claim_verification-gpt-3.5-turbo.jsonl\n",
      "Batch(id='batch_66fab40836488190b04c523f9f96deb0', completion_window='24h', created_at=1727706120, endpoint='/v1/chat/completions', input_file_id='file-nupmoQL5npaU5gkBBllRfZmR', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727706453, error_file_id=None, errors=None, expired_at=None, expires_at=1727792520, failed_at=None, finalizing_at=1727706441, in_progress_at=1727706121, metadata=None, output_file_id='file-g0zmrL72N3aTtfQcXuqzMDeC', request_counts=BatchRequestCounts(completed=168, failed=0, total=168))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/german_dpr-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-german_dpr-claim_verification-gpt-4o.jsonl\n",
      "Batch(id='batch_66fab40e5f088190858a872468271f05', completion_window='24h', created_at=1727706126, endpoint='/v1/chat/completions', input_file_id='file-wzoLslZonddlCOYffrptRssU', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727707287, error_file_id=None, errors=None, expired_at=None, expires_at=1727792526, failed_at=None, finalizing_at=1727707270, in_progress_at=1727706127, metadata=None, output_file_id='file-yUPnw1mX9YHwCC6xWrdagIuM', request_counts=BatchRequestCounts(completed=168, failed=0, total=168))\n",
      "_______________\n",
      "/Users/lukasellinger/PycharmProjects/evaluating_factuality_word_definitions/data/evaluation/german_dpr-claim_verification/zero_shot/input/input_zero_shot_connected_prompt-german_dpr-claim_verification-gpt-4o-mini.jsonl\n",
      "Batch(id='batch_66fab4143ef88190bae98447a6b77b83', completion_window='24h', created_at=1727706132, endpoint='/v1/chat/completions', input_file_id='file-kZeT6OKn3mutZg3fnydcHYHo', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1727707788, error_file_id=None, errors=None, expired_at=None, expires_at=1727792532, failed_at=None, finalizing_at=1727707768, in_progress_at=1727706133, metadata=None, output_file_id='file-0UzKb6Nf5d1hLIQxXQ01Kdb3', request_counts=BatchRequestCounts(completed=168, failed=0, total=168))\n",
      "_______________\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:57:15.913989Z",
     "start_time": "2024-09-30T14:56:53.039621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file_name, batch_job in batch_jobs.items():\n",
    "    output_file_name = file_name.replace('input', 'raw_output')\n",
    "    openai_fetcher.get_batch_result(output_file_name, batch_job)"
   ],
   "id": "c72b099bc661f41",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 Zero Shot",
   "id": "5a152c88dce51794"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:52:05.999616Z",
     "start_time": "2024-09-30T09:52:05.996129Z"
    }
   },
   "cell_type": "code",
   "source": "file_base_name = str(EVALUATION_DIR / '{dataset}/zero_shot/{type}/{type}_zero_shot-{dataset}-{model}.jsonl')",
   "id": "581980b95c784bd5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:41:02.555292Z",
     "start_time": "2024-09-25T14:41:02.276321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in tqdm(datasets.items()):\n",
    "    dataset = config['dataset']\n",
    "    for model in models:\n",
    "        create_tasks(\n",
    "            dataset,\n",
    "            model,\n",
    "            file_base_name.format(type='input', dataset=dataset_name, model=model),\n",
    "            create_long_prompt\n",
    "        )"
   ],
   "id": "27e5f48b5824d684",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once input files are created, head to 2, to manually fetch your outputs",
   "id": "e127b7d91fc33df8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T09:52:25.148220Z",
     "start_time": "2024-09-30T09:52:10.953479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    dataset = config['dataset']\n",
    "    print(f\"{dataset_name}: _________________________\")\n",
    "    for model in models:\n",
    "        file_name = file_base_name.format(type='raw_output', dataset=dataset_name, model=model)\n",
    "        if not Path(file_name).exists():\n",
    "            continue\n",
    "        print(f\"Evaluating {dataset_name} with {model}...\")\n",
    "        outputs = process_results(file_base_name.format(type='raw_output', dataset=dataset_name, model=model), dataset, translations=False)\n",
    "        fh.write(file_base_name.format(type='output', dataset=dataset_name, model=model), outputs, mode='w')"
   ],
   "id": "a50d27f53a05d16a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: _________________________\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9474    0.4286    0.5902        84\n",
      "           1     0.6308    0.9762    0.7664        84\n",
      "\n",
      "    accuracy                         0.7024       168\n",
      "   macro avg     0.7891    0.7024    0.6783       168\n",
      "weighted avg     0.7891    0.7024    0.6783       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9375    0.4348    0.5941        69\n",
      "           1     0.6355    0.9714    0.7684        70\n",
      "\n",
      "    accuracy                         0.7050       139\n",
      "   macro avg     0.7865    0.7031    0.6812       139\n",
      "weighted avg     0.7854    0.7050    0.6818       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9355    0.6905    0.7945        84\n",
      "           1     0.7547    0.9524    0.8421        84\n",
      "\n",
      "    accuracy                         0.8214       168\n",
      "   macro avg     0.8451    0.8214    0.8183       168\n",
      "weighted avg     0.8451    0.8214    0.8183       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9184    0.6522    0.7627        69\n",
      "           1     0.7333    0.9429    0.8250        70\n",
      "\n",
      "    accuracy                         0.7986       139\n",
      "   macro avg     0.8259    0.7975    0.7939       139\n",
      "weighted avg     0.8252    0.7986    0.7941       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9383    0.9048    0.9212        84\n",
      "           1     0.9080    0.9405    0.9240        84\n",
      "\n",
      "    accuracy                         0.9226       168\n",
      "   macro avg     0.9232    0.9226    0.9226       168\n",
      "weighted avg     0.9232    0.9226    0.9226       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9385    0.8841    0.9104        69\n",
      "           1     0.8919    0.9429    0.9167        70\n",
      "\n",
      "    accuracy                         0.9137       139\n",
      "   macro avg     0.9152    0.9135    0.9136       139\n",
      "weighted avg     0.9150    0.9137    0.9136       139\n",
      "\n",
      "german_wiktionary-claim_verification-mini: _________________________\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9545    0.2100    0.3443       100\n",
      "           1     0.5562    0.9900    0.7122       100\n",
      "\n",
      "    accuracy                         0.6000       200\n",
      "   macro avg     0.7554    0.6000    0.5282       200\n",
      "weighted avg     0.7554    0.6000    0.5282       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.1975    0.3265        81\n",
      "           1     0.5455    0.9873    0.7027        79\n",
      "\n",
      "    accuracy                         0.5875       160\n",
      "   macro avg     0.7433    0.5924    0.5146       160\n",
      "weighted avg     0.7458    0.5875    0.5123       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8772    0.5000    0.6369       100\n",
      "           1     0.6503    0.9300    0.7654       100\n",
      "\n",
      "    accuracy                         0.7150       200\n",
      "   macro avg     0.7638    0.7150    0.7012       200\n",
      "weighted avg     0.7638    0.7150    0.7012       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8542    0.5062    0.6357        81\n",
      "           1     0.6429    0.9114    0.7539        79\n",
      "\n",
      "    accuracy                         0.7063       160\n",
      "   macro avg     0.7485    0.7088    0.6948       160\n",
      "weighted avg     0.7498    0.7063    0.6941       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8788    0.8700    0.8744       100\n",
      "           1     0.8713    0.8800    0.8756       100\n",
      "\n",
      "    accuracy                         0.8750       200\n",
      "   macro avg     0.8750    0.8750    0.8750       200\n",
      "weighted avg     0.8750    0.8750    0.8750       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8537    0.8642    0.8589        81\n",
      "           1     0.8590    0.8481    0.8535        79\n",
      "\n",
      "    accuracy                         0.8562       160\n",
      "   macro avg     0.8563    0.8561    0.8562       160\n",
      "weighted avg     0.8563    0.8562    0.8562       160\n",
      "\n",
      "squad-claim_verification: _________________________\n",
      "Evaluating squad-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8816    0.8481    0.8645        79\n",
      "           1     0.8537    0.8861    0.8696        79\n",
      "\n",
      "    accuracy                         0.8671       158\n",
      "   macro avg     0.8676    0.8671    0.8670       158\n",
      "weighted avg     0.8676    0.8671    0.8670       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8852    0.8571    0.8710        63\n",
      "           1     0.8615    0.8889    0.8750        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8734    0.8730    0.8730       126\n",
      "weighted avg     0.8734    0.8730    0.8730       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7976    0.8481    0.8221        79\n",
      "           1     0.8378    0.7848    0.8105        79\n",
      "\n",
      "    accuracy                         0.8165       158\n",
      "   macro avg     0.8177    0.8165    0.8163       158\n",
      "weighted avg     0.8177    0.8165    0.8163       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7941    0.8571    0.8244        63\n",
      "           1     0.8448    0.7778    0.8099        63\n",
      "\n",
      "    accuracy                         0.8175       126\n",
      "   macro avg     0.8195    0.8175    0.8172       126\n",
      "weighted avg     0.8195    0.8175    0.8172       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7429    0.9873    0.8478        79\n",
      "           1     0.9811    0.6582    0.7879        79\n",
      "\n",
      "    accuracy                         0.8228       158\n",
      "   macro avg     0.8620    0.8228    0.8179       158\n",
      "weighted avg     0.8620    0.8228    0.8179       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7654    0.9841    0.8611        63\n",
      "           1     0.9778    0.6984    0.8148        63\n",
      "\n",
      "    accuracy                         0.8413       126\n",
      "   macro avg     0.8716    0.8413    0.8380       126\n",
      "weighted avg     0.8716    0.8413    0.8380       126\n",
      "\n",
      "shroom-claim_verification: _________________________\n",
      "Evaluating shroom-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8362    0.3368    0.4802       288\n",
      "           1     0.5727    0.9309    0.7091       275\n",
      "\n",
      "    accuracy                         0.6270       563\n",
      "   macro avg     0.7045    0.6339    0.5947       563\n",
      "weighted avg     0.7075    0.6270    0.5920       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.3417    0.4847       278\n",
      "           1     0.5724    0.9280    0.7081       264\n",
      "\n",
      "    accuracy                         0.6273       542\n",
      "   macro avg     0.7029    0.6349    0.5964       542\n",
      "weighted avg     0.7063    0.6273    0.5935       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7892    0.5590    0.6545       288\n",
      "           1     0.6462    0.8436    0.7319       275\n",
      "\n",
      "    accuracy                         0.6980       563\n",
      "   macro avg     0.7177    0.7013    0.6932       563\n",
      "weighted avg     0.7194    0.6980    0.6923       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7908    0.5576    0.6540       278\n",
      "           1     0.6445    0.8447    0.7311       264\n",
      "\n",
      "    accuracy                         0.6974       542\n",
      "   macro avg     0.7177    0.7011    0.6926       542\n",
      "weighted avg     0.7196    0.6974    0.6916       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7556    0.5903    0.6628       288\n",
      "           1     0.6509    0.8000    0.7178       275\n",
      "\n",
      "    accuracy                         0.6927       563\n",
      "   macro avg     0.7032    0.6951    0.6903       563\n",
      "weighted avg     0.7044    0.6927    0.6896       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7581    0.5863    0.6613       278\n",
      "           1     0.6483    0.8030    0.7174       264\n",
      "\n",
      "    accuracy                         0.6919       542\n",
      "   macro avg     0.7032    0.6947    0.6893       542\n",
      "weighted avg     0.7046    0.6919    0.6886       542\n",
      "\n",
      "german_wiktionary-claim_verification-large: _________________________\n",
      "Evaluating german_wiktionary-claim_verification-large with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9020    0.5410    0.6763      5000\n",
      "           1     0.6722    0.9412    0.7843      5000\n",
      "\n",
      "    accuracy                         0.7411     10000\n",
      "   macro avg     0.7871    0.7411    0.7303     10000\n",
      "weighted avg     0.7871    0.7411    0.7303     10000\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8953    0.5213    0.6590      3938\n",
      "           1     0.6596    0.9383    0.7746      3892\n",
      "\n",
      "    accuracy                         0.7286      7830\n",
      "   macro avg     0.7774    0.7298    0.7168      7830\n",
      "weighted avg     0.7781    0.7286    0.7165      7830\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 German Prompt",
   "id": "b7c351ab08dcdf4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:37:07.196817Z",
     "start_time": "2024-09-30T08:37:07.191812Z"
    }
   },
   "cell_type": "code",
   "source": "file_base_name = str(EVALUATION_DIR / '{dataset}/zero_shot/{type}/{type}_zero_shot_german_prompt-{dataset}-{model}.jsonl')",
   "id": "773b9decd7b3cd2b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T14:44:28.597500Z",
     "start_time": "2024-09-25T14:44:28.588394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in tqdm(datasets.items()):\n",
    "    if config['lang'] == 'en':\n",
    "        continue\n",
    "        \n",
    "    dataset = config['dataset']\n",
    "    for model in models:\n",
    "        create_tasks(\n",
    "            dataset,\n",
    "            model,\n",
    "            file_base_name.format(type='input', dataset=dataset_name, model=model),\n",
    "            create_long_german_prompt\n",
    "        )"
   ],
   "id": "79af2cf756059094",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10433.59it/s]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once input files are created, head to 2, to manually fetch your outputs",
   "id": "c5d5d6afdfc1e349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:37:26.970165Z",
     "start_time": "2024-09-30T08:37:24.595405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    dataset = config['dataset']\n",
    "    print(f\"{dataset_name}: _________________________\")\n",
    "    for model in models:\n",
    "        file_name = file_base_name.format(type='raw_output', dataset=dataset_name, model=model)\n",
    "        if not Path(file_name).exists():\n",
    "            continue\n",
    "        print(f\"Evaluating {dataset_name} with {model}...\")\n",
    "        outputs = process_results(file_base_name.format(type='raw_output', dataset=dataset_name, model=model), dataset, translations=False, lang='de')\n",
    "        fh.write(file_base_name.format(type='output', dataset=dataset_name, model=model), outputs, mode='w')"
   ],
   "id": "1b6993d3782d7b9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: _________________________\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.9048    0.8492        84\n",
      "           1     0.8904    0.7738    0.8280        84\n",
      "\n",
      "    accuracy                         0.8393       168\n",
      "   macro avg     0.8452    0.8393    0.8386       168\n",
      "weighted avg     0.8452    0.8393    0.8386       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8243    0.8841    0.8531        69\n",
      "           1     0.8769    0.8143    0.8444        70\n",
      "\n",
      "    accuracy                         0.8489       139\n",
      "   macro avg     0.8506    0.8492    0.8488       139\n",
      "weighted avg     0.8508    0.8489    0.8488       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8472    0.7262    0.7821        84\n",
      "           1     0.7604    0.8690    0.8111        84\n",
      "\n",
      "    accuracy                         0.7976       168\n",
      "   macro avg     0.8038    0.7976    0.7966       168\n",
      "weighted avg     0.8038    0.7976    0.7966       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8475    0.7246    0.7812        69\n",
      "           1     0.7625    0.8714    0.8133        70\n",
      "\n",
      "    accuracy                         0.7986       139\n",
      "   macro avg     0.8050    0.7980    0.7973       139\n",
      "weighted avg     0.8047    0.7986    0.7974       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8780    0.8571    0.8675        84\n",
      "           1     0.8605    0.8810    0.8706        84\n",
      "\n",
      "    accuracy                         0.8690       168\n",
      "   macro avg     0.8693    0.8690    0.8690       168\n",
      "weighted avg     0.8693    0.8690    0.8690       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8676    0.8551    0.8613        69\n",
      "           1     0.8592    0.8714    0.8652        70\n",
      "\n",
      "    accuracy                         0.8633       139\n",
      "   macro avg     0.8634    0.8633    0.8633       139\n",
      "weighted avg     0.8634    0.8633    0.8633       139\n",
      "\n",
      "german_wiktionary-claim_verification-mini: _________________________\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8367    0.8200    0.8283       100\n",
      "           1     0.8235    0.8400    0.8317       100\n",
      "\n",
      "    accuracy                         0.8300       200\n",
      "   macro avg     0.8301    0.8300    0.8300       200\n",
      "weighted avg     0.8301    0.8300    0.8300       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.8025    0.8176        81\n",
      "           1     0.8049    0.8354    0.8199        79\n",
      "\n",
      "    accuracy                         0.8187       160\n",
      "   macro avg     0.8191    0.8190    0.8187       160\n",
      "weighted avg     0.8193    0.8187    0.8187       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8205    0.6400    0.7191       100\n",
      "           1     0.7049    0.8600    0.7748       100\n",
      "\n",
      "    accuracy                         0.7500       200\n",
      "   macro avg     0.7627    0.7500    0.7469       200\n",
      "weighted avg     0.7627    0.7500    0.7469       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8387    0.6420    0.7273        81\n",
      "           1     0.7041    0.8734    0.7797        79\n",
      "\n",
      "    accuracy                         0.7562       160\n",
      "   macro avg     0.7714    0.7577    0.7535       160\n",
      "weighted avg     0.7722    0.7562    0.7531       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8723    0.8200    0.8454       100\n",
      "           1     0.8302    0.8800    0.8544       100\n",
      "\n",
      "    accuracy                         0.8500       200\n",
      "   macro avg     0.8513    0.8500    0.8499       200\n",
      "weighted avg     0.8513    0.8500    0.8499       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.7901    0.8366        81\n",
      "           1     0.8068    0.8987    0.8503        79\n",
      "\n",
      "    accuracy                         0.8438       160\n",
      "   macro avg     0.8479    0.8444    0.8435       160\n",
      "weighted avg     0.8484    0.8438    0.8434       160\n",
      "\n",
      "squad-claim_verification: _________________________\n",
      "shroom-claim_verification: _________________________\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5 Connected Claim",
   "id": "45a47e8a6b78bddb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:03:21.351835Z",
     "start_time": "2024-09-30T15:03:21.348378Z"
    }
   },
   "cell_type": "code",
   "source": "file_base_name = str(EVALUATION_DIR / '{dataset}/zero_shot/{type}/{type}_zero_shot_connected_prompt-{dataset}-{model}.jsonl')",
   "id": "6cb1eb9c06fb7b48",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:16:26.633499Z",
     "start_time": "2024-09-30T14:16:26.170437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in tqdm(datasets.items()):      \n",
    "    dataset = config['dataset']\n",
    "    for model in models:\n",
    "        create_tasks(\n",
    "            dataset,\n",
    "            model,\n",
    "            file_base_name.format(type='input', dataset=dataset_name, model=model),\n",
    "            create_connected_prompt\n",
    "        )"
   ],
   "id": "5d130385190b0038",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  8.82it/s]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once input files are created, head to 2, to manually fetch your outputs",
   "id": "e4b0ed35248042a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:03:29.795679Z",
     "start_time": "2024-09-30T15:03:25.107491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    dataset = config['dataset']\n",
    "    print(f\"{dataset_name}: _________________________\")\n",
    "    for model in models:\n",
    "        file_name = file_base_name.format(type='raw_output', dataset=dataset_name, model=model)\n",
    "        if not Path(file_name).exists():\n",
    "            continue\n",
    "        print(f\"Evaluating {dataset_name} with {model}...\")\n",
    "        outputs = process_results(file_base_name.format(type='raw_output', dataset=dataset_name, model=model), dataset, translations=False, lang='de')\n",
    "        fh.write(file_base_name.format(type='output', dataset=dataset_name, model=model), outputs, mode='w')"
   ],
   "id": "5de73f92d37bd2dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: _________________________\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9241    0.8690    0.8957        84\n",
      "           1     0.8764    0.9286    0.9017        84\n",
      "\n",
      "    accuracy                         0.8988       168\n",
      "   macro avg     0.9002    0.8988    0.8987       168\n",
      "weighted avg     0.9002    0.8988    0.8987       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9355    0.8406    0.8855        69\n",
      "           1     0.8571    0.9429    0.8980        70\n",
      "\n",
      "    accuracy                         0.8921       139\n",
      "   macro avg     0.8963    0.8917    0.8917       139\n",
      "weighted avg     0.8960    0.8921    0.8918       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8387    0.9286    0.8814        84\n",
      "           1     0.9200    0.8214    0.8679        84\n",
      "\n",
      "    accuracy                         0.8750       168\n",
      "   macro avg     0.8794    0.8750    0.8746       168\n",
      "weighted avg     0.8794    0.8750    0.8746       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8630    0.9130    0.8873        69\n",
      "           1     0.9091    0.8571    0.8824        70\n",
      "\n",
      "    accuracy                         0.8849       139\n",
      "   macro avg     0.8861    0.8851    0.8848       139\n",
      "weighted avg     0.8862    0.8849    0.8848       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8235    1.0000    0.9032        84\n",
      "           1     1.0000    0.7857    0.8800        84\n",
      "\n",
      "    accuracy                         0.8929       168\n",
      "   macro avg     0.9118    0.8929    0.8916       168\n",
      "weighted avg     0.9118    0.8929    0.8916       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8214    1.0000    0.9020        69\n",
      "           1     1.0000    0.7857    0.8800        70\n",
      "\n",
      "    accuracy                         0.8921       139\n",
      "   macro avg     0.9107    0.8929    0.8910       139\n",
      "weighted avg     0.9114    0.8921    0.8909       139\n",
      "\n",
      "german_wiktionary-claim_verification-mini: _________________________\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7935    0.7300    0.7604       100\n",
      "           1     0.7500    0.8100    0.7788       100\n",
      "\n",
      "    accuracy                         0.7700       200\n",
      "   macro avg     0.7717    0.7700    0.7696       200\n",
      "weighted avg     0.7717    0.7700    0.7696       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7973    0.7284    0.7613        81\n",
      "           1     0.7442    0.8101    0.7758        79\n",
      "\n",
      "    accuracy                         0.7688       160\n",
      "   macro avg     0.7707    0.7693    0.7685       160\n",
      "weighted avg     0.7711    0.7688    0.7684       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7266    0.9300    0.8158       100\n",
      "           1     0.9028    0.6500    0.7558       100\n",
      "\n",
      "    accuracy                         0.7900       200\n",
      "   macro avg     0.8147    0.7900    0.7858       200\n",
      "weighted avg     0.8147    0.7900    0.7858       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7212    0.9259    0.8108        81\n",
      "           1     0.8929    0.6329    0.7407        79\n",
      "\n",
      "    accuracy                         0.7812       160\n",
      "   macro avg     0.8070    0.7794    0.7758       160\n",
      "weighted avg     0.8059    0.7812    0.7762       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6835    0.9500    0.7950       100\n",
      "           1     0.9180    0.5600    0.6957       100\n",
      "\n",
      "    accuracy                         0.7550       200\n",
      "   macro avg     0.8007    0.7550    0.7453       200\n",
      "weighted avg     0.8007    0.7550    0.7453       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6754    0.9506    0.7897        81\n",
      "           1     0.9130    0.5316    0.6720        79\n",
      "\n",
      "    accuracy                         0.7438       160\n",
      "   macro avg     0.7942    0.7411    0.7309       160\n",
      "weighted avg     0.7928    0.7438    0.7316       160\n",
      "\n",
      "squad-claim_verification: _________________________\n",
      "Evaluating squad-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.9114    0.8834        79\n",
      "           1     0.9054    0.8481    0.8758        79\n",
      "\n",
      "    accuracy                         0.8797       158\n",
      "   macro avg     0.8813    0.8797    0.8796       158\n",
      "weighted avg     0.8813    0.8797    0.8796       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9048    0.9048    0.9048        63\n",
      "           1     0.9048    0.9048    0.9048        63\n",
      "\n",
      "    accuracy                         0.9048       126\n",
      "   macro avg     0.9048    0.9048    0.9048       126\n",
      "weighted avg     0.9048    0.9048    0.9048       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8409    0.9367    0.8862        79\n",
      "           1     0.9286    0.8228    0.8725        79\n",
      "\n",
      "    accuracy                         0.8797       158\n",
      "   macro avg     0.8847    0.8797    0.8794       158\n",
      "weighted avg     0.8847    0.8797    0.8794       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.9524    0.9023        63\n",
      "           1     0.9464    0.8413    0.8908        63\n",
      "\n",
      "    accuracy                         0.8968       126\n",
      "   macro avg     0.9018    0.8968    0.8965       126\n",
      "weighted avg     0.9018    0.8968    0.8965       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8085    0.9620    0.8786        79\n",
      "           1     0.9531    0.7722    0.8531        79\n",
      "\n",
      "    accuracy                         0.8671       158\n",
      "   macro avg     0.8808    0.8671    0.8659       158\n",
      "weighted avg     0.8808    0.8671    0.8659       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8133    0.9683    0.8841        63\n",
      "           1     0.9608    0.7778    0.8596        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8871    0.8730    0.8719       126\n",
      "weighted avg     0.8871    0.8730    0.8719       126\n",
      "\n",
      "shroom-claim_verification: _________________________\n",
      "Evaluating shroom-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7962    0.4340    0.5618       288\n",
      "           1     0.5985    0.8836    0.7137       275\n",
      "\n",
      "    accuracy                         0.6536       563\n",
      "   macro avg     0.6974    0.6588    0.6377       563\n",
      "weighted avg     0.6996    0.6536    0.6360       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7908    0.4353    0.5615       278\n",
      "           1     0.5964    0.8788    0.7106       264\n",
      "\n",
      "    accuracy                         0.6513       542\n",
      "   macro avg     0.6936    0.6570    0.6360       542\n",
      "weighted avg     0.6961    0.6513    0.6341       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7467    0.5833    0.6550       288\n",
      "           1     0.6450    0.7927    0.7113       275\n",
      "\n",
      "    accuracy                         0.6856       563\n",
      "   macro avg     0.6958    0.6880    0.6831       563\n",
      "weighted avg     0.6970    0.6856    0.6825       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7477    0.5863    0.6573       278\n",
      "           1     0.6451    0.7917    0.7109       264\n",
      "\n",
      "    accuracy                         0.6863       542\n",
      "   macro avg     0.6964    0.6890    0.6841       542\n",
      "weighted avg     0.6977    0.6863    0.6834       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7310    0.7361    0.7336       288\n",
      "           1     0.7216    0.7164    0.7190       275\n",
      "\n",
      "    accuracy                         0.7265       563\n",
      "   macro avg     0.7263    0.7262    0.7263       563\n",
      "weighted avg     0.7264    0.7265    0.7264       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7266    0.7266    0.7266       278\n",
      "           1     0.7121    0.7121    0.7121       264\n",
      "\n",
      "    accuracy                         0.7196       542\n",
      "   macro avg     0.7194    0.7194    0.7194       542\n",
      "weighted avg     0.7196    0.7196    0.7196       542\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5 Ablation Translated Claims",
   "id": "b0f8f3670917df8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:39:24.823265Z",
     "start_time": "2024-09-30T08:39:24.819484Z"
    }
   },
   "cell_type": "code",
   "source": "file_base_name = str(EVALUATION_DIR / '{dataset}/ablation_translated_claims/{type}/{type}_ablation_translated_claims-{dataset}-{model}.jsonl')",
   "id": "68913ba371e2a6e1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 19.95it/s]\n"
     ]
    }
   ],
   "execution_count": 38,
   "source": [
    "for dataset_name, config in tqdm(datasets.items()):\n",
    "    if config['lang'] == 'en':\n",
    "        continue\n",
    "\n",
    "    dataset = config['dataset']    \n",
    "    for model in models:\n",
    "        create_tasks(\n",
    "            dataset,\n",
    "            model,\n",
    "            file_base_name.format(type='input', dataset=dataset_name, model=model),\n",
    "            create_long_translation_prompt\n",
    "        )"
   ],
   "id": "c80afac9e66af1d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once input files are created, head to 2, to manually fetch your outputs",
   "id": "8d2c3ea8259a6a50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T08:39:35.064192Z",
     "start_time": "2024-09-30T08:39:33.727148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    if config['lang'] == 'en':\n",
    "        continue\n",
    "        \n",
    "    dataset = config['dataset']\n",
    "    print(f\"{dataset_name}: _________________________\")\n",
    "    for model in models:\n",
    "        print(f\"Evaluating {dataset_name} with {model}...\")\n",
    "        outputs = process_results(file_base_name.format(type='raw_output', dataset=dataset_name, model=model), dataset, translations=False)\n",
    "        fh.write(file_base_name.format(type='output', dataset=dataset_name, model=model), outputs, mode='w')"
   ],
   "id": "54336d77347614db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: _________________________\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9403    0.7500    0.8344        84\n",
      "           1     0.7921    0.9524    0.8649        84\n",
      "\n",
      "    accuracy                         0.8512       168\n",
      "   macro avg     0.8662    0.8512    0.8497       168\n",
      "weighted avg     0.8662    0.8512    0.8497       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9259    0.7246    0.8130        69\n",
      "           1     0.7765    0.9429    0.8516        70\n",
      "\n",
      "    accuracy                         0.8345       139\n",
      "   macro avg     0.8512    0.8337    0.8323       139\n",
      "weighted avg     0.8507    0.8345    0.8324       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8706    0.8810    0.8757        84\n",
      "           1     0.8795    0.8690    0.8743        84\n",
      "\n",
      "    accuracy                         0.8750       168\n",
      "   macro avg     0.8751    0.8750    0.8750       168\n",
      "weighted avg     0.8751    0.8750    0.8750       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8806    0.8551    0.8676        69\n",
      "           1     0.8611    0.8857    0.8732        70\n",
      "\n",
      "    accuracy                         0.8705       139\n",
      "   macro avg     0.8709    0.8704    0.8704       139\n",
      "weighted avg     0.8708    0.8705    0.8705       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.9524    0.8889        84\n",
      "           1     0.9444    0.8095    0.8718        84\n",
      "\n",
      "    accuracy                         0.8810       168\n",
      "   macro avg     0.8889    0.8810    0.8803       168\n",
      "weighted avg     0.8889    0.8810    0.8803       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.9420    0.8844        69\n",
      "           1     0.9344    0.8143    0.8702        70\n",
      "\n",
      "    accuracy                         0.8777       139\n",
      "   macro avg     0.8839    0.8782    0.8773       139\n",
      "weighted avg     0.8842    0.8777    0.8772       139\n",
      "\n",
      "german_wiktionary-claim_verification-mini: _________________________\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8421    0.4800    0.6115       100\n",
      "           1     0.6364    0.9100    0.7490       100\n",
      "\n",
      "    accuracy                         0.6950       200\n",
      "   macro avg     0.7392    0.6950    0.6802       200\n",
      "weighted avg     0.7392    0.6950    0.6802       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8864    0.4815    0.6240        81\n",
      "           1     0.6379    0.9367    0.7590        79\n",
      "\n",
      "    accuracy                         0.7063       160\n",
      "   macro avg     0.7621    0.7091    0.6915       160\n",
      "weighted avg     0.7637    0.7063    0.6906       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7629    0.7400    0.7513       100\n",
      "           1     0.7476    0.7700    0.7586       100\n",
      "\n",
      "    accuracy                         0.7550       200\n",
      "   macro avg     0.7552    0.7550    0.7549       200\n",
      "weighted avg     0.7552    0.7550    0.7549       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7468    0.7284    0.7375        81\n",
      "           1     0.7284    0.7468    0.7375        79\n",
      "\n",
      "    accuracy                         0.7375       160\n",
      "   macro avg     0.7376    0.7376    0.7375       160\n",
      "weighted avg     0.7377    0.7375    0.7375       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6884    0.9500    0.7983       100\n",
      "           1     0.9194    0.5700    0.7037       100\n",
      "\n",
      "    accuracy                         0.7600       200\n",
      "   macro avg     0.8039    0.7600    0.7510       200\n",
      "weighted avg     0.8039    0.7600    0.7510       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.9506    0.8063        81\n",
      "           1     0.9200    0.5823    0.7132        79\n",
      "\n",
      "    accuracy                         0.7688       160\n",
      "   macro avg     0.8100    0.7664    0.7597       160\n",
      "weighted avg     0.8086    0.7688    0.7603       160\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6 Zero Shot Single Facts",
   "id": "e665b558ede09f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:20:28.836156Z",
     "start_time": "2024-09-30T15:20:28.833116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "claim_split_types = [\n",
    "    'DisSim_facts',\n",
    "    'T5SplitRephrase_facts',\n",
    "    'Factscore_facts'\n",
    "]"
   ],
   "id": "36f7a32c6652cd96",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:20:30.835824Z",
     "start_time": "2024-09-30T15:20:30.832307Z"
    }
   },
   "cell_type": "code",
   "source": "file_base_name = str(EVALUATION_DIR / '{dataset}/zero_shot_{split_type}/{type}/{type}_zero_shot_{split_type}-{dataset}-{model}.jsonl')",
   "id": "243f1e8f685e7a25",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T11:42:39.103104Z",
     "start_time": "2024-09-30T11:42:36.997189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in tqdm(datasets.items()):\n",
    "    dataset = config['dataset']\n",
    "    for model in models:\n",
    "        for split_type in claim_split_types:\n",
    "            tasks = []\n",
    "            for idx, entry in enumerate(dataset):\n",
    "                word = entry.get('english_word', entry['word'])\n",
    "                atomic_facts = entry[split_type].split('--;--')\n",
    "    \n",
    "                for aidx, atomic_fact in enumerate(atomic_facts):\n",
    "                    tasks.append(build_task(f'{idx}-{aidx}', model, create_long_prompt_from_claim(word, atomic_fact)))\n",
    "            fh.write(file_base_name.format(type='input', dataset=dataset_name, model=model, split_type=split_type), tasks, mode='w')"
   ],
   "id": "494c10852271c29d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once input files are created, head to 2, to manually fetch your outputs",
   "id": "2f903b7824971f9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:20:36.420625Z",
     "start_time": "2024-09-30T15:20:36.409260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(dataset_name, dataset, model, split_type):\n",
    "    print(f\"Evaluating {dataset_name} with {model} - {split_type}...\")\n",
    "    results = fh.read(file_base_name.format(type='raw_output', dataset=dataset_name, model=model, split_type=split_type))\n",
    "    \n",
    "    data_dict = init_data_dict(dataset)\n",
    "    process_results(results, dataset, data_dict, split_type)\n",
    "    gt_labels, pr_labels, wiki_gt_labels, wiki_pr_labels = generate_labels(data_dict)\n",
    "    \n",
    "    fh.write(file_base_name.format(type='output', dataset=dataset_name, model=model, split_type=split_type), data_dict.values(), mode='w')    \n",
    "    report = classification_report(gt_labels, pr_labels, zero_division=0, digits=4)\n",
    "    wiki_report = classification_report(wiki_gt_labels, wiki_pr_labels, zero_division=0, digits=4)\n",
    "    print('Report all entries:')\n",
    "    print(report)\n",
    "    print('Filtered Report for entries with evidence in wikipedia:')\n",
    "    print(wiki_report)\n",
    "\n",
    "def init_data_dict(dataset):\n",
    "    data_dict = {}\n",
    "    for entry in dataset:\n",
    "        data_dict[entry['id']] = {\n",
    "            'id': entry['id'],\n",
    "            'word': entry['word'],\n",
    "            'claim': entry['claim'],\n",
    "            'label': entry['label'],\n",
    "            'predicted': -1,\n",
    "            'atoms': [],\n",
    "            'in_wiki': entry['in_wiki']\n",
    "        }\n",
    "    return data_dict\n",
    "\n",
    "def process_results(results, dataset, data_dict, split_type):\n",
    "    for res in results:\n",
    "        task_id = res['custom_id']\n",
    "        index = int(task_id.split('-')[1])\n",
    "        atom_index = int(task_id.split('-')[2])\n",
    "        \n",
    "        entry = dataset[index]\n",
    "        atom = entry[split_type].split('--;--')[atom_index]\n",
    "        \n",
    "        predicted = get_openai_prediction(res['response']['body'])\n",
    "        if predicted == 'UNKOWN':\n",
    "            txt_answer = res['response']['body']['choices'][0]['message']['content']\n",
    "            predicted = parse_model_answer(txt_answer)\n",
    "        \n",
    "        data_dict[entry['id']]['atoms'].append({\"atom\": atom, \"predicted\": predicted})\n",
    "\n",
    "def generate_labels(data_dict):\n",
    "    gt_labels, wiki_gt_labels = [], []\n",
    "    pr_labels, wiki_pr_labels = [], []\n",
    "    \n",
    "    for entry_id, entry in data_dict.items():\n",
    "        all_predictions = [decision['predicted'] == 'SUPPORTED' for decision in entry['atoms']]\n",
    "        average_is_supported = np.mean(all_predictions)\n",
    "        data_dict[entry_id]['predicted'] = 'SUPPORTED' if average_is_supported == 1 else 'NOT_SUPPORTED'\n",
    "                \n",
    "        gt_label = 1 if entry['label'] == 'SUPPORTED' else 0\n",
    "        pr_label = 1 if entry['predicted'] == 'SUPPORTED' else 0\n",
    "        gt_labels.append(gt_label)\n",
    "        pr_labels.append(pr_label)\n",
    "        \n",
    "        if entry['in_wiki'] == 'Yes':\n",
    "            wiki_gt_labels.append(gt_label)\n",
    "            wiki_pr_labels.append(pr_label)\n",
    "            \n",
    "    return gt_labels, pr_labels, wiki_gt_labels, wiki_pr_labels"
   ],
   "id": "16ed886b227f27fc",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:20:57.244294Z",
     "start_time": "2024-09-30T15:20:37.891269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    dataset = config['dataset']\n",
    "    print(f\"{dataset_name}: _________________________\")\n",
    "    for model in models:\n",
    "        for split_type in claim_split_types:\n",
    "            evaluate_model(dataset_name, dataset, model, split_type)"
   ],
   "id": "e412f2206d5ec6b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: _________________________\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8144    0.9405    0.8729        84\n",
      "           1     0.9296    0.7857    0.8516        84\n",
      "\n",
      "    accuracy                         0.8631       168\n",
      "   macro avg     0.8720    0.8631    0.8623       168\n",
      "weighted avg     0.8720    0.8631    0.8623       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8025    0.9420    0.8667        69\n",
      "           1     0.9310    0.7714    0.8438        70\n",
      "\n",
      "    accuracy                         0.8561       139\n",
      "   macro avg     0.8668    0.8567    0.8552       139\n",
      "weighted avg     0.8672    0.8561    0.8551       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8041    0.9286    0.8619        84\n",
      "           1     0.9155    0.7738    0.8387        84\n",
      "\n",
      "    accuracy                         0.8512       168\n",
      "   macro avg     0.8598    0.8512    0.8503       168\n",
      "weighted avg     0.8598    0.8512    0.8503       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7975    0.9130    0.8514        69\n",
      "           1     0.9000    0.7714    0.8308        70\n",
      "\n",
      "    accuracy                         0.8417       139\n",
      "   macro avg     0.8487    0.8422    0.8411       139\n",
      "weighted avg     0.8491    0.8417    0.8410       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-3.5-turbo - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7570    0.9643    0.8482        84\n",
      "           1     0.9508    0.6905    0.8000        84\n",
      "\n",
      "    accuracy                         0.8274       168\n",
      "   macro avg     0.8539    0.8274    0.8241       168\n",
      "weighted avg     0.8539    0.8274    0.8241       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.9565    0.8408        69\n",
      "           1     0.9412    0.6857    0.7934        70\n",
      "\n",
      "    accuracy                         0.8201       139\n",
      "   macro avg     0.8456    0.8211    0.8171       139\n",
      "weighted avg     0.8463    0.8201    0.8169       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7257    0.9762    0.8325        84\n",
      "           1     0.9636    0.6310    0.7626        84\n",
      "\n",
      "    accuracy                         0.8036       168\n",
      "   macro avg     0.8447    0.8036    0.7975       168\n",
      "weighted avg     0.8447    0.8036    0.7975       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7204    0.9710    0.8272        69\n",
      "           1     0.9565    0.6286    0.7586        70\n",
      "\n",
      "    accuracy                         0.7986       139\n",
      "   macro avg     0.8385    0.7998    0.7929       139\n",
      "weighted avg     0.8393    0.7986    0.7926       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7368    1.0000    0.8485        84\n",
      "           1     1.0000    0.6429    0.7826        84\n",
      "\n",
      "    accuracy                         0.8214       168\n",
      "   macro avg     0.8684    0.8214    0.8155       168\n",
      "weighted avg     0.8684    0.8214    0.8155       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7340    1.0000    0.8466        69\n",
      "           1     1.0000    0.6429    0.7826        70\n",
      "\n",
      "    accuracy                         0.8201       139\n",
      "   macro avg     0.8670    0.8214    0.8146       139\n",
      "weighted avg     0.8680    0.8201    0.8144       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o-mini - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7155    0.9881    0.8300        84\n",
      "           1     0.9808    0.6071    0.7500        84\n",
      "\n",
      "    accuracy                         0.7976       168\n",
      "   macro avg     0.8481    0.7976    0.7900       168\n",
      "weighted avg     0.8481    0.7976    0.7900       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7158    0.9855    0.8293        69\n",
      "           1     0.9773    0.6143    0.7544        70\n",
      "\n",
      "    accuracy                         0.7986       139\n",
      "   macro avg     0.8465    0.7999    0.7918       139\n",
      "weighted avg     0.8475    0.7986    0.7916       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6803    0.9881    0.8058        84\n",
      "           1     0.9783    0.5357    0.6923        84\n",
      "\n",
      "    accuracy                         0.7619       168\n",
      "   macro avg     0.8293    0.7619    0.7491       168\n",
      "weighted avg     0.8293    0.7619    0.7491       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6602    0.9855    0.7907        69\n",
      "           1     0.9722    0.5000    0.6604        70\n",
      "\n",
      "    accuracy                         0.7410       139\n",
      "   macro avg     0.8162    0.7428    0.7255       139\n",
      "weighted avg     0.8173    0.7410    0.7251       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7434    1.0000    0.8528        84\n",
      "           1     1.0000    0.6548    0.7914        84\n",
      "\n",
      "    accuracy                         0.8274       168\n",
      "   macro avg     0.8717    0.8274    0.8221       168\n",
      "weighted avg     0.8717    0.8274    0.8221       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7419    1.0000    0.8519        69\n",
      "           1     1.0000    0.6571    0.7931        70\n",
      "\n",
      "    accuracy                         0.8273       139\n",
      "   macro avg     0.8710    0.8286    0.8225       139\n",
      "weighted avg     0.8719    0.8273    0.8223       139\n",
      "\n",
      "Evaluating german_dpr-claim_verification with gpt-4o - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6694    0.9881    0.7981        84\n",
      "           1     0.9773    0.5119    0.6719        84\n",
      "\n",
      "    accuracy                         0.7500       168\n",
      "   macro avg     0.8233    0.7500    0.7350       168\n",
      "weighted avg     0.8233    0.7500    0.7350       168\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6602    0.9855    0.7907        69\n",
      "           1     0.9722    0.5000    0.6604        70\n",
      "\n",
      "    accuracy                         0.7410       139\n",
      "   macro avg     0.8162    0.7428    0.7255       139\n",
      "weighted avg     0.8173    0.7410    0.7251       139\n",
      "\n",
      "german_wiktionary-claim_verification-mini: _________________________\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7155    0.8300    0.7685       100\n",
      "           1     0.7976    0.6700    0.7283       100\n",
      "\n",
      "    accuracy                         0.7500       200\n",
      "   macro avg     0.7566    0.7500    0.7484       200\n",
      "weighted avg     0.7566    0.7500    0.7484       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6979    0.8272    0.7571        81\n",
      "           1     0.7812    0.6329    0.6993        79\n",
      "\n",
      "    accuracy                         0.7312       160\n",
      "   macro avg     0.7396    0.7300    0.7282       160\n",
      "weighted avg     0.7391    0.7312    0.7285       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7131    0.8700    0.7838       100\n",
      "           1     0.8333    0.6500    0.7303       100\n",
      "\n",
      "    accuracy                         0.7600       200\n",
      "   macro avg     0.7732    0.7600    0.7571       200\n",
      "weighted avg     0.7732    0.7600    0.7571       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6900    0.8519    0.7624        81\n",
      "           1     0.8000    0.6076    0.6906        79\n",
      "\n",
      "    accuracy                         0.7312       160\n",
      "   macro avg     0.7450    0.7297    0.7265       160\n",
      "weighted avg     0.7443    0.7312    0.7270       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-3.5-turbo - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6571    0.9200    0.7667       100\n",
      "           1     0.8667    0.5200    0.6500       100\n",
      "\n",
      "    accuracy                         0.7200       200\n",
      "   macro avg     0.7619    0.7200    0.7083       200\n",
      "weighted avg     0.7619    0.7200    0.7083       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6518    0.9012    0.7565        81\n",
      "           1     0.8333    0.5063    0.6299        79\n",
      "\n",
      "    accuracy                         0.7063       160\n",
      "   macro avg     0.7426    0.7038    0.6932       160\n",
      "weighted avg     0.7414    0.7063    0.6940       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6250    0.9500    0.7540       100\n",
      "           1     0.8958    0.4300    0.5811       100\n",
      "\n",
      "    accuracy                         0.6900       200\n",
      "   macro avg     0.7604    0.6900    0.6675       200\n",
      "weighted avg     0.7604    0.6900    0.6675       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6032    0.9383    0.7343        81\n",
      "           1     0.8529    0.3671    0.5133        79\n",
      "\n",
      "    accuracy                         0.6562       160\n",
      "   macro avg     0.7281    0.6527    0.6238       160\n",
      "weighted avg     0.7265    0.6562    0.6252       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6643    0.9500    0.7819       100\n",
      "           1     0.9123    0.5200    0.6624       100\n",
      "\n",
      "    accuracy                         0.7350       200\n",
      "   macro avg     0.7883    0.7350    0.7222       200\n",
      "weighted avg     0.7883    0.7350    0.7222       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6417    0.9506    0.7662        81\n",
      "           1     0.9000    0.4557    0.6050        79\n",
      "\n",
      "    accuracy                         0.7063       160\n",
      "   macro avg     0.7708    0.7032    0.6856       160\n",
      "weighted avg     0.7692    0.7063    0.6866       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o-mini - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5975    0.9500    0.7336       100\n",
      "           1     0.8780    0.3600    0.5106       100\n",
      "\n",
      "    accuracy                         0.6550       200\n",
      "   macro avg     0.7378    0.6550    0.6221       200\n",
      "weighted avg     0.7378    0.6550    0.6221       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5891    0.9383    0.7238        81\n",
      "           1     0.8387    0.3291    0.4727        79\n",
      "\n",
      "    accuracy                         0.6375       160\n",
      "   macro avg     0.7139    0.6337    0.5983       160\n",
      "weighted avg     0.7124    0.6375    0.5998       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5799    0.9800    0.7286       100\n",
      "           1     0.9355    0.2900    0.4427       100\n",
      "\n",
      "    accuracy                         0.6350       200\n",
      "   macro avg     0.7577    0.6350    0.5857       200\n",
      "weighted avg     0.7577    0.6350    0.5857       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5766    0.9753    0.7248        81\n",
      "           1     0.9130    0.2658    0.4118        79\n",
      "\n",
      "    accuracy                         0.6250       160\n",
      "   macro avg     0.7448    0.6206    0.5683       160\n",
      "weighted avg     0.7427    0.6250    0.5702       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6258    0.9700    0.7608       100\n",
      "           1     0.9333    0.4200    0.5793       100\n",
      "\n",
      "    accuracy                         0.6950       200\n",
      "   macro avg     0.7796    0.6950    0.6700       200\n",
      "weighted avg     0.7796    0.6950    0.6700       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6094    0.9630    0.7464        81\n",
      "           1     0.9062    0.3671    0.5225        79\n",
      "\n",
      "    accuracy                         0.6687       160\n",
      "   macro avg     0.7578    0.6650    0.6345       160\n",
      "weighted avg     0.7560    0.6687    0.6359       160\n",
      "\n",
      "Evaluating german_wiktionary-claim_verification-mini with gpt-4o - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5868    0.9800    0.7341       100\n",
      "           1     0.9394    0.3100    0.4662       100\n",
      "\n",
      "    accuracy                         0.6450       200\n",
      "   macro avg     0.7631    0.6450    0.6001       200\n",
      "weighted avg     0.7631    0.6450    0.6001       200\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5852    0.9753    0.7315        81\n",
      "           1     0.9200    0.2911    0.4423        79\n",
      "\n",
      "    accuracy                         0.6375       160\n",
      "   macro avg     0.7526    0.6332    0.5869       160\n",
      "weighted avg     0.7505    0.6375    0.5887       160\n",
      "\n",
      "squad-claim_verification: _________________________\n",
      "Evaluating squad-claim_verification with gpt-3.5-turbo - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8471    0.9114    0.8780        79\n",
      "           1     0.9041    0.8354    0.8684        79\n",
      "\n",
      "    accuracy                         0.8734       158\n",
      "   macro avg     0.8756    0.8734    0.8732       158\n",
      "weighted avg     0.8756    0.8734    0.8732       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8507    0.9048    0.8769        63\n",
      "           1     0.8983    0.8413    0.8689        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8745    0.8730    0.8729       126\n",
      "weighted avg     0.8745    0.8730    0.8729       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-3.5-turbo - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8256    0.8987    0.8606        79\n",
      "           1     0.8889    0.8101    0.8477        79\n",
      "\n",
      "    accuracy                         0.8544       158\n",
      "   macro avg     0.8572    0.8544    0.8541       158\n",
      "weighted avg     0.8572    0.8544    0.8541       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8615    0.8889    0.8750        63\n",
      "           1     0.8852    0.8571    0.8710        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8734    0.8730    0.8730       126\n",
      "weighted avg     0.8734    0.8730    0.8730       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-3.5-turbo - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7872    0.9367    0.8555        79\n",
      "           1     0.9219    0.7468    0.8252        79\n",
      "\n",
      "    accuracy                         0.8418       158\n",
      "   macro avg     0.8546    0.8418    0.8403       158\n",
      "weighted avg     0.8546    0.8418    0.8403       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8310    0.9365    0.8806        63\n",
      "           1     0.9273    0.8095    0.8644        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8791    0.8730    0.8725       126\n",
      "weighted avg     0.8791    0.8730    0.8725       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o-mini - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7895    0.9494    0.8621        79\n",
      "           1     0.9365    0.7468    0.8310        79\n",
      "\n",
      "    accuracy                         0.8481       158\n",
      "   macro avg     0.8630    0.8481    0.8465       158\n",
      "weighted avg     0.8630    0.8481    0.8465       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8133    0.9683    0.8841        63\n",
      "           1     0.9608    0.7778    0.8596        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8871    0.8730    0.8719       126\n",
      "weighted avg     0.8871    0.8730    0.8719       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o-mini - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7872    0.9367    0.8555        79\n",
      "           1     0.9219    0.7468    0.8252        79\n",
      "\n",
      "    accuracy                         0.8418       158\n",
      "   macro avg     0.8546    0.8418    0.8403       158\n",
      "weighted avg     0.8546    0.8418    0.8403       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8219    0.9524    0.8824        63\n",
      "           1     0.9434    0.7937    0.8621        63\n",
      "\n",
      "    accuracy                         0.8730       126\n",
      "   macro avg     0.8827    0.8730    0.8722       126\n",
      "weighted avg     0.8827    0.8730    0.8722       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o-mini - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7426    0.9494    0.8333        79\n",
      "           1     0.9298    0.6709    0.7794        79\n",
      "\n",
      "    accuracy                         0.8101       158\n",
      "   macro avg     0.8362    0.8101    0.8064       158\n",
      "weighted avg     0.8362    0.8101    0.8064       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7821    0.9683    0.8652        63\n",
      "           1     0.9583    0.7302    0.8288        63\n",
      "\n",
      "    accuracy                         0.8492       126\n",
      "   macro avg     0.8702    0.8492    0.8470       126\n",
      "weighted avg     0.8702    0.8492    0.8470       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8125    0.9873    0.8914        79\n",
      "           1     0.9839    0.7722    0.8652        79\n",
      "\n",
      "    accuracy                         0.8797       158\n",
      "   macro avg     0.8982    0.8797    0.8783       158\n",
      "weighted avg     0.8982    0.8797    0.8783       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8267    0.9841    0.8986        63\n",
      "           1     0.9804    0.7937    0.8772        63\n",
      "\n",
      "    accuracy                         0.8889       126\n",
      "   macro avg     0.9035    0.8889    0.8879       126\n",
      "weighted avg     0.9035    0.8889    0.8879       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7755    0.9620    0.8588        79\n",
      "           1     0.9500    0.7215    0.8201        79\n",
      "\n",
      "    accuracy                         0.8418       158\n",
      "   macro avg     0.8628    0.8418    0.8395       158\n",
      "weighted avg     0.8628    0.8418    0.8395       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7895    0.9524    0.8633        63\n",
      "           1     0.9400    0.7460    0.8319        63\n",
      "\n",
      "    accuracy                         0.8492       126\n",
      "   macro avg     0.8647    0.8492    0.8476       126\n",
      "weighted avg     0.8647    0.8492    0.8476       126\n",
      "\n",
      "Evaluating squad-claim_verification with gpt-4o - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7222    0.9873    0.8342        79\n",
      "           1     0.9800    0.6203    0.7597        79\n",
      "\n",
      "    accuracy                         0.8038       158\n",
      "   macro avg     0.8511    0.8038    0.7970       158\n",
      "weighted avg     0.8511    0.8038    0.7970       158\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7654    0.9841    0.8611        63\n",
      "           1     0.9778    0.6984    0.8148        63\n",
      "\n",
      "    accuracy                         0.8413       126\n",
      "   macro avg     0.8716    0.8413    0.8380       126\n",
      "weighted avg     0.8716    0.8413    0.8380       126\n",
      "\n",
      "shroom-claim_verification: _________________________\n",
      "Evaluating shroom-claim_verification with gpt-3.5-turbo - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7655    0.3854    0.5127       288\n",
      "           1     0.5766    0.8764    0.6955       275\n",
      "\n",
      "    accuracy                         0.6252       563\n",
      "   macro avg     0.6710    0.6309    0.6041       563\n",
      "weighted avg     0.6732    0.6252    0.6020       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7692    0.3957    0.5226       278\n",
      "           1     0.5789    0.8750    0.6968       264\n",
      "\n",
      "    accuracy                         0.6292       542\n",
      "   macro avg     0.6741    0.6353    0.6097       542\n",
      "weighted avg     0.6765    0.6292    0.6074       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-3.5-turbo - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7901    0.4965    0.6098       288\n",
      "           1     0.6204    0.8618    0.7215       275\n",
      "\n",
      "    accuracy                         0.6750       563\n",
      "   macro avg     0.7052    0.6792    0.6656       563\n",
      "weighted avg     0.7072    0.6750    0.6643       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7874    0.4928    0.6062       278\n",
      "           1     0.6168    0.8598    0.7184       264\n",
      "\n",
      "    accuracy                         0.6716       542\n",
      "   macro avg     0.7021    0.6763    0.6623       542\n",
      "weighted avg     0.7043    0.6716    0.6608       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-3.5-turbo - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7112    0.6840    0.6973       288\n",
      "           1     0.6818    0.7091    0.6952       275\n",
      "\n",
      "    accuracy                         0.6963       563\n",
      "   macro avg     0.6965    0.6966    0.6963       563\n",
      "weighted avg     0.6968    0.6963    0.6963       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7105    0.6799    0.6949       278\n",
      "           1     0.6775    0.7083    0.6926       264\n",
      "\n",
      "    accuracy                         0.6937       542\n",
      "   macro avg     0.6940    0.6941    0.6937       542\n",
      "weighted avg     0.6945    0.6937    0.6938       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o-mini - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7148    0.6528    0.6824       288\n",
      "           1     0.6667    0.7273    0.6957       275\n",
      "\n",
      "    accuracy                         0.6892       563\n",
      "   macro avg     0.6907    0.6900    0.6890       563\n",
      "weighted avg     0.6913    0.6892    0.6889       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7194    0.6547    0.6855       278\n",
      "           1     0.6678    0.7311    0.6980       264\n",
      "\n",
      "    accuracy                         0.6919       542\n",
      "   macro avg     0.6936    0.6929    0.6918       542\n",
      "weighted avg     0.6943    0.6919    0.6916       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o-mini - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7303    0.6771    0.7027       288\n",
      "           1     0.6858    0.7382    0.7110       275\n",
      "\n",
      "    accuracy                         0.7069       563\n",
      "   macro avg     0.7081    0.7076    0.7069       563\n",
      "weighted avg     0.7086    0.7069    0.7068       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7402    0.6763    0.7068       278\n",
      "           1     0.6875    0.7500    0.7174       264\n",
      "\n",
      "    accuracy                         0.7122       542\n",
      "   macro avg     0.7138    0.7131    0.7121       542\n",
      "weighted avg     0.7145    0.7122    0.7119       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o-mini - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6271    0.7708    0.6916       288\n",
      "           1     0.6842    0.5200    0.5909       275\n",
      "\n",
      "    accuracy                         0.6483       563\n",
      "   macro avg     0.6557    0.6454    0.6412       563\n",
      "weighted avg     0.6550    0.6483    0.6424       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6313    0.7698    0.6937       278\n",
      "           1     0.6847    0.5265    0.5953       264\n",
      "\n",
      "    accuracy                         0.6513       542\n",
      "   macro avg     0.6580    0.6481    0.6445       542\n",
      "weighted avg     0.6573    0.6513    0.6458       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o - DisSim_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7055    0.7986    0.7492       288\n",
      "           1     0.7553    0.6509    0.6992       275\n",
      "\n",
      "    accuracy                         0.7265       563\n",
      "   macro avg     0.7304    0.7248    0.7242       563\n",
      "weighted avg     0.7298    0.7265    0.7248       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7093    0.7986    0.7513       278\n",
      "           1     0.7555    0.6553    0.7018       264\n",
      "\n",
      "    accuracy                         0.7288       542\n",
      "   macro avg     0.7324    0.7269    0.7265       542\n",
      "weighted avg     0.7318    0.7288    0.7272       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o - T5SplitRephrase_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7039    0.7431    0.7230       288\n",
      "           1     0.7143    0.6727    0.6929       275\n",
      "\n",
      "    accuracy                         0.7087       563\n",
      "   macro avg     0.7091    0.7079    0.7079       563\n",
      "weighted avg     0.7090    0.7087    0.7083       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7103    0.7410    0.7254       278\n",
      "           1     0.7143    0.6818    0.6977       264\n",
      "\n",
      "    accuracy                         0.7122       542\n",
      "   macro avg     0.7123    0.7114    0.7115       542\n",
      "weighted avg     0.7123    0.7122    0.7119       542\n",
      "\n",
      "Evaluating shroom-claim_verification with gpt-4o - Factscore_facts...\n",
      "Report all entries:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6361    0.8681    0.7342       288\n",
      "           1     0.7765    0.4800    0.5933       275\n",
      "\n",
      "    accuracy                         0.6785       563\n",
      "   macro avg     0.7063    0.6740    0.6637       563\n",
      "weighted avg     0.7047    0.6785    0.6654       563\n",
      "\n",
      "Filtered Report for entries with evidence in wikipedia:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6349    0.8633    0.7317       278\n",
      "           1     0.7683    0.4773    0.5888       264\n",
      "\n",
      "    accuracy                         0.6753       542\n",
      "   macro avg     0.7016    0.6703    0.6602       542\n",
      "weighted avg     0.6999    0.6753    0.6621       542\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d23815a0046be6b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
