{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T14:16:51.418803Z",
     "start_time": "2024-07-09T14:16:46.470163Z"
    }
   },
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "from config import OPEN_AI_TOKEN\n",
    "from config import PROJECT_DIR\n",
    "from general_utils.reader import JSONLineReader\n",
    "from tqdm import tqdm\n",
    "from general_utils.utils import parse_model_answer, get_openai_prediction"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:16:51.503573Z",
     "start_time": "2024-07-09T14:16:51.423726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI(api_key=OPEN_AI_TOKEN)\n",
    "fh = JSONLineReader()"
   ],
   "id": "9814017a89e4850",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:16:56.379553Z",
     "start_time": "2024-07-09T14:16:51.508084Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"lukasellinger/german_dpr_claim_verification_dissim-v1\").get('train')",
   "id": "5dec1c04ed69dce9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T11:09:40.684434Z",
     "start_time": "2024-07-09T11:09:40.679067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_prediction(claim, model=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    temperature=0.1,\n",
    "    logprobs=True,\n",
    "    top_logprobs=5,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'Input: {claim} True or False?\\nOutput:'\n",
    "        }\n",
    "    ],\n",
    "    )\n",
    "    txt_output = response.choices[0].message.content\n",
    "    prediction = get_openai_prediction(response)\n",
    "    if prediction == 'UNKOWN':\n",
    "        prediction = parse_model_answer(txt_output)\n",
    "    return txt_output, prediction"
   ],
   "id": "e992acf418da2343",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T11:09:45.221551Z",
     "start_time": "2024-07-09T11:09:43.651988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing on a few examples\n",
    "for entry in dataset.select(range(3)):\n",
    "    word = entry.get('word')\n",
    "    claim = f\"{word}: {entry['claim']}\"\n",
    "    output, prediction = get_prediction(claim)\n",
    "    print(f\"WORD: {word}\\nOVERVIEW: {claim}\\n\\nOUTPUT: {output}\\nPREDICTION: {prediction}\")\n",
    "    print(\"\\n\\n----------------------------\\n\\n\")"
   ],
   "id": "4d3dec8eb1877d89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: Liebe\n",
      "OVERVIEW: Liebe: inniges Gefühl der Zuneigung für jemanden oder für etwas\n",
      "\n",
      "OUTPUT: True\n",
      "PREDICTIONS: SUPPORTED\n",
      "\n",
      "\n",
      "----------------------------\n",
      "\n",
      "\n",
      "WORD: Liebe\n",
      "OVERVIEW: Liebe: sexuell oder erotisch motivierte Neigung zu jemandem oder zu einer Sache\n",
      "\n",
      "OUTPUT: True\n",
      "PREDICTIONS: SUPPORTED\n",
      "\n",
      "\n",
      "----------------------------\n",
      "\n",
      "\n",
      "WORD: Liebe\n",
      "OVERVIEW: Liebe: Geschlechtsakt; Akt der körperlichen Vereinigung in Folge von 2\n",
      "\n",
      "OUTPUT: False\n",
      "PREDICTIONS: NOT_SUPPORTED\n",
      "\n",
      "\n",
      "----------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T09:06:41.440113Z",
     "start_time": "2024-07-09T09:04:17.344938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    claim = f\"{word}: {entry['claim']}\"\n",
    "    generated_answer = get_prediction(claim, model='gpt-4o').lower()\n",
    "    predicted = parse_model_answer(generated_answer)\n",
    "    \n",
    "    lines.append({\n",
    "        'id': entry['id'],\n",
    "        'word': entry['word'],\n",
    "        'claim': claim,\n",
    "        'predicted': predicted,\n",
    "        'label': entry['label']\n",
    "    })\n",
    "        \n",
    "fh.write('output_gpt4o.jsonl', lines)"
   ],
   "id": "8b7585ffcce72a1b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [02:24<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Task",
   "id": "9abc1eca3b5c4a3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zero Shot Task",
   "id": "61dd576910944a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T10:07:32.973926Z",
     "start_time": "2024-07-09T10:07:32.905507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating an array of json tasks\n",
    "model = \"gpt-3.5-turbo\"\n",
    "tasks = []\n",
    "\n",
    "for idx, entry in enumerate(dataset):\n",
    "    word = entry['word']\n",
    "    claim = f\"{word}: {entry['claim']}\"\n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{idx}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"temperature\": 0.1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f'Input: {claim} True or False?\\nOutput:'\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    tasks.append(task)"
   ],
   "id": "aa992895c8a298e8",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Atomic Fact Task",
   "id": "ac71a0dc37a6ede2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:17:01.301357Z",
     "start_time": "2024-07-09T14:16:56.384464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from general_utils.atomic_facts import AtomicFactPromptGenerator\n",
    "\n",
    "# Creating an array of json tasks\n",
    "prompt_generator = AtomicFactPromptGenerator(demon_dir='../factscore/demos')\n",
    "\n",
    "model = \"gpt-3.5-turbo\"\n",
    "tasks = []\n",
    "\n",
    "for idx, entry in enumerate(dataset):\n",
    "    word = entry.get('english_word')\n",
    "    claim = f\"{word}: {entry['english_claim']}\"\n",
    "    messages = prompt_generator.create_prompt_from_sentence(claim)\n",
    "    task = {\n",
    "        \"custom_id\": f\"task-{idx}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model,\n",
    "            \"temperature\": 0.1,\n",
    "            \"messages\": messages,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    tasks.append(task)"
   ],
   "id": "914da79112317039",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lukasellinger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:17:07.063044Z",
     "start_time": "2024-07-09T14:17:07.051773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating the file\n",
    "identification = 'german_dpr_facts-gpt3_5-turbo'\n",
    "file_name = PROJECT_DIR.joinpath(f'dataset/openai/batch_{identification}.jsonl')\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj) + '\\n')"
   ],
   "id": "9d5300dacbeeb275",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:17:09.940645Z",
     "start_time": "2024-07-09T14:17:08.190108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_file = client.files.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ],
   "id": "f432a5941e9dffa4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:17:12.648940Z",
     "start_time": "2024-07-09T14:17:12.643416Z"
    }
   },
   "cell_type": "code",
   "source": "print(batch_file)",
   "id": "4cac3ab3d4043760",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-ZLrSEvrONfVaWGwidT9vZY96', bytes=253871, created_at=1720534629, filename='batch_german_dpr_facts-gpt3_5-turbo.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating batch job",
   "id": "e0a00013634b86c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:17:17.615274Z",
     "start_time": "2024-07-09T14:17:16.939305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ],
   "id": "ea068487952b9971",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:22:25.789699Z",
     "start_time": "2024-07-09T14:22:25.357156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job)"
   ],
   "id": "86eae459775ab997",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_QWlXIxtxZrVu7AwTwYWd8j1v', completion_window='24h', created_at=1720534637, endpoint='/v1/chat/completions', input_file_id='file-ZLrSEvrONfVaWGwidT9vZY96', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1720534935, error_file_id=None, errors=None, expired_at=None, expires_at=1720621037, failed_at=None, finalizing_at=1720534928, in_progress_at=1720534638, metadata=None, output_file_id='file-yDMqmxjw0Zp1n4hRiQVOFRp2', request_counts=BatchRequestCounts(completed=168, failed=0, total=168))\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Retrieving results",
   "id": "f90e9bc9873363d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:22:32.319677Z",
     "start_time": "2024-07-09T14:22:31.372889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content"
   ],
   "id": "56258b406252fdd7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:22:34.225620Z",
     "start_time": "2024-07-09T14:22:34.219720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_file_name = f\"batch_{identification}_results.jsonl\"\n",
    "\n",
    "with open(result_file_name, 'wb') as file:\n",
    "    file.write(result)"
   ],
   "id": "ed9aff84d6a10152",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:22:38.145253Z",
     "start_time": "2024-07-09T14:22:38.136791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading data from saved file\n",
    "results = fh.read(result_file_name)"
   ],
   "id": "c0fa0c3e354d8719",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T10:14:38.472967Z",
     "start_time": "2024-07-09T10:14:38.386919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines = []\n",
    "for res in results:\n",
    "    task_id = res['custom_id']\n",
    "    # Getting index from task id\n",
    "    index = task_id.split('-')[-1]\n",
    "    entry = dataset[int(index)]\n",
    "    claim = entry['claim']\n",
    "    word = entry['word']\n",
    "    generated_answer = res['response']['body']['choices'][0]['message']['content'].lower()\n",
    "    predicted = parse_model_answer(generated_answer)\n",
    "\n",
    "    lines.append({\n",
    "        'id': entry['id'],\n",
    "        'word': entry['word'],\n",
    "        'claim': claim,\n",
    "        'predicted': predicted,\n",
    "        'label': entry['label']\n",
    "    })\n",
    "    \n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/openai/output_{identification}.jsonl', lines))"
   ],
   "id": "e318636baca39631",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:26:14.763520Z",
     "start_time": "2024-07-09T14:26:14.722830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from general_utils.reader import JSONReader\n",
    "import re\n",
    "\n",
    "lines = {}\n",
    "for res in results:\n",
    "    task_id = res['custom_id']\n",
    "    # Getting index from task id\n",
    "    index = task_id.split('-')[-1]\n",
    "    entry = dataset[int(index)]\n",
    "    claim = entry['claim']\n",
    "    word = entry['word']\n",
    "    generated_answer = res['response']['body']['choices'][0]['message']['content']\n",
    "    facts = []\n",
    "    for line in generated_answer.split('\\n'):\n",
    "        fact_match = re.match(r'^\\d+\\.(.*)', line)\n",
    "        if fact_match:\n",
    "            facts.append(fact_match.group(1).strip())\n",
    "        else:\n",
    "            print(f'{entry[\"id\"]} - {generated_answer}')\n",
    "    lines[entry['id']] = facts\n",
    "\n",
    "JSONReader().write(PROJECT_DIR.joinpath(f'dataset/openai/output_{identification}.json'), lines)"
   ],
   "id": "7996c291a2e6d5d6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a14e98df70716c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
