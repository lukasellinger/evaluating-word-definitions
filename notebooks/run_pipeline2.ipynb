{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:56:27.580130Z",
     "start_time": "2024-07-29T09:56:27.524244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset.def_dataset import DefinitionDataset, Fact\n",
    "from transformers import AutoTokenizer\n",
    "from models.evidence_selection_model import EvidenceSelectionModel\n",
    "from models.claim_verification_model import ClaimVerificationModel\n",
    "import torch\n",
    "from transformers import AutoModel, AutoModelForSequenceClassification\n",
    "from general_utils.fever_scorer import fever_score\n",
    "from pipeline.pipeline_old import TestPipeline, WikiPipeline\n",
    "from general_utils.utils import build_fever_instance\n",
    "from general_utils.utils import convert_document_id_to_word\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from general_utils.reader import JSONLineReader\n",
    "from datasets import load_dataset"
   ],
   "id": "f64dbae6394734e0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:56:06.862467Z",
     "start_time": "2024-07-29T09:56:06.859173Z"
    }
   },
   "cell_type": "code",
   "source": "fh = JSONLineReader()",
   "id": "d8cc73ac2e8d8783",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:56:27.518401Z",
     "start_time": "2024-07-29T09:56:07.413540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "selection_model_name = 'Snowflake/snowflake-arctic-embed-m-long'\n",
    "selection_model_tokenizer_base = AutoTokenizer.from_pretrained(selection_model_name)\n",
    "selection_model_raw_base = AutoModel.from_pretrained(selection_model_name, trust_remote_code=True, add_pooling_layer=False, safe_serialization=True)\n",
    "selection_model_base = EvidenceSelectionModel(selection_model_raw_base).to(device)\n",
    "\n",
    "selection_model_name = 'lukasellinger/evidence_selection_model-v2'\n",
    "selection_model_tokenizer = AutoTokenizer.from_pretrained(selection_model_name)\n",
    "selection_model_raw = AutoModel.from_pretrained(selection_model_name, trust_remote_code=True, add_pooling_layer=False, safe_serialization=True)\n",
    "selection_model = EvidenceSelectionModel(selection_model_raw).to(device)\n",
    "\n",
    "verification_model_name = 'MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7'\n",
    "verification_model_tokenizer_base = AutoTokenizer.from_pretrained(verification_model_name)\n",
    "verification_model_raw_base = AutoModelForSequenceClassification.from_pretrained(verification_model_name)\n",
    "verification_model_base = ClaimVerificationModel(verification_model_raw_base).to(device)\n",
    "\n",
    "verification_model_name = 'lukasellinger/claim_verification_model-v1'\n",
    "verification_model_tokenizer = AutoTokenizer.from_pretrained(verification_model_name)\n",
    "verification_model_raw = AutoModelForSequenceClassification.from_pretrained(verification_model_name)\n",
    "verification_model = ClaimVerificationModel(verification_model_raw).to(device)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T15:21:23.720273Z",
     "start_time": "2024-07-03T15:20:40.615331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_dataset = load_dataset(\"lukasellinger/fever_evidence_selection-v1\", cache_dir=None).get('dev')\n",
    "# dataset = DefinitionDataset(raw_dataset, tokenizer=None, model='claim_verification')\n",
    "print(raw_dataset.features)\n",
    "\n",
    "test_pipeline = TestPipeline(selection_model=selection_model,selection_model_tokenizer=selection_model_tokenizer, \n",
    "                             verification_model=verification_model, verification_model_tokenizer=verification_model_tokenizer)\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "fever_instances = []\n",
    "for entry in tqdm(raw_dataset):\n",
    "    word = entry.get('document_id')\n",
    "    fallback_word = convert_document_id_to_word(word)\n",
    "\n",
    "    output = test_pipeline.verify(word, entry['short_claim'], fallback_word, split_facts=False)\n",
    "    if output.get('factuality') == 1:\n",
    "        factuality = Fact.SUPPORTED\n",
    "    else:\n",
    "        factuality = Fact.NOT_SUPPORTED\n",
    "    pr_labels.append(factuality.to_factuality())\n",
    "\n",
    "    if entry['label'] == 'SUPPORTS':\n",
    "        label = Fact.SUPPORTED\n",
    "    else:\n",
    "        label = Fact.NOT_SUPPORTED\n",
    "    gt_labels.append(label.to_factuality())\n",
    "\n",
    "    evidence = entry['evidence_lines'].split(';')\n",
    "    #predicted_label = output.get('factualities')[0]  # TODO add atomic fact support\n",
    "    #predicted_evidence = output.get('evidences')\n",
    "    predicted_evidence = [(x, y) for (x, y, z) in output.get('evidences')]\n",
    "    fever_instance = build_fever_instance(label.name, evidence, entry['document_id'], factuality, predicted_evidence)\n",
    "    fever_instances.append(fever_instance)\n",
    "\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0))\n",
    "strict_score, label_accuracy, precision, recall, f1 = fever_score(fever_instances)\n",
    "\n",
    "print(strict_score)\n",
    "print(label_accuracy)\n",
    "print(precision)  # TP / TP + FP not too important, rather at least one TP than none\n",
    "print(recall)     # more important\n",
    "print(f1)"
   ],
   "id": "ef957373e0ab88e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='int64', id=None), 'claim': Value(dtype='string', id=None), 'short_claim': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None), 'document_id': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None), 'lines': Value(dtype='string', id=None), 'evidence_lines': Value(dtype='string', id=None), 'atomic_facts': Value(dtype='string', id=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1978 [00:37<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:57:47.016509Z",
     "start_time": "2024-07-29T09:57:33.450036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "offline_wiki = 'lukasellinger/wiki_dump_2024-07-08'\n",
    "pipeline_base = WikiPipeline(selection_model=selection_model_base, selection_model_tokenizer=selection_model_tokenizer_base, word_lang='de', use_offline_wiki=offline_wiki)\n",
    "pipeline = WikiPipeline(selection_model=selection_model, selection_model_tokenizer=selection_model_tokenizer, word_lang='de', use_offline_wiki=offline_wiki)"
   ],
   "id": "2fb0c78e3d2ad221",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GermanDPR",
   "id": "338a13b04efdf0f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:57:53.032059Z",
     "start_time": "2024-07-29T09:57:47.018971Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"lukasellinger/german_dpr_claim_verification_dissim-v1\").get('train')",
   "id": "f10bf94861830a9c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:11:14.349588Z",
     "start_time": "2024-07-18T14:11:14.338987Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset.features)",
   "id": "c4f9f7e49fc60fca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='int64', id=None), 'question': Value(dtype='string', id=None), 'claim': Value(dtype='string', id=None), 'english_claim': Value(dtype='string', id=None), 'fact': Value(dtype='string', id=None), 'word': Value(dtype='string', id=None), 'english_word': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None), 'document_search_word': Value(dtype='string', id=None), 'connected_claim': Value(dtype='string', id=None), 'atomic_facts_old': Value(dtype='string', id=None), 'atomic_facts': Value(dtype='string', id=None), 'factscore_facts': Value(dtype='string', id=None), 'in_wiki': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:58:53.128675Z",
     "start_time": "2024-07-29T09:58:53.121545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_factuality(factualities, not_in_wiki, lines, pr_labels, gt_labels):\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    in_wiki = True\n",
    "    if factuality.get('factuality') == 1:\n",
    "        predicted = Fact.SUPPORTED\n",
    "    elif factuality.get('factuality') == -1:\n",
    "        not_in_wiki += 1\n",
    "        in_wiki = False\n",
    "    else:\n",
    "        predicted = Fact.NOT_SUPPORTED\n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    \n",
    "    lines.append({\n",
    "        'id': entry['id'],\n",
    "        'word': entry['word'],\n",
    "        'claim': claim,\n",
    "        'label': entry['label'],\n",
    "        'predicted': predicted.name,\n",
    "        'atoms': factuality.get('factualities'),\n",
    "        'selected_evidences': factuality.get('evidences')\n",
    "    })"
   ],
   "id": "75d03c25fb944097",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:58:54.134542Z",
     "start_time": "2024-07-29T09:58:54.128723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_prediction(factuality):\n",
    "    in_wiki = True\n",
    "    predicted = None\n",
    "    if factuality.get('factuality') == 1:\n",
    "        predicted = Fact.SUPPORTED\n",
    "    elif factuality.get('factuality') == -1:\n",
    "        in_wiki = False\n",
    "    else:\n",
    "        predicted = Fact.NOT_SUPPORTED\n",
    "        \n",
    "    return predicted, in_wiki\n",
    "\n",
    "def build_output(entry, claim, predicted, factuality):\n",
    "    return {\n",
    "        'id': entry['id'],\n",
    "        'word': entry['word'],\n",
    "        'claim': claim,\n",
    "        'label': entry['label'],\n",
    "        'predicted': predicted.name if predicted else None,\n",
    "        'atoms': factuality.get('factualities'),\n",
    "        'selected_evidences': factuality.get('evidences')\n",
    "    }"
   ],
   "id": "4feba98bb681f249",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## {word} : {claim}",
   "id": "c21fe5d11fa9c9ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:18:43.700739Z",
     "start_time": "2024-07-18T14:14:09.577271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_word_claim_finetuned'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = entry.get('english_claim', entry['claim'])\n",
    "\n",
    "    factuality = pipeline.verify(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "aa4856295ab68dca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:34<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.9130    0.7925        69\n",
      "           1     0.8776    0.6143    0.7227        70\n",
      "\n",
      "    accuracy                         0.7626       139\n",
      "   macro avg     0.7888    0.7637    0.7576       139\n",
      "weighted avg     0.7894    0.7626    0.7573       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:22:35.164140Z",
     "start_time": "2024-07-18T14:18:43.703928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_word_claim_base'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = entry.get('english_claim', entry['claim'])\n",
    "\n",
    "    factuality = pipeline_base.verify(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "66dba0c9a6259997",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [03:51<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6739    0.8986    0.7702        69\n",
      "           1     0.8511    0.5714    0.6838        70\n",
      "\n",
      "    accuracy                         0.7338       139\n",
      "   macro avg     0.7625    0.7350    0.7270       139\n",
      "weighted avg     0.7631    0.7338    0.7267       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## connected sentence",
   "id": "5ec2ab5bb3598379"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:19:37.159229Z",
     "start_time": "2024-07-29T09:59:00.658340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_connected_finetuned'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = entry.get('connected_claim')\n",
    "\n",
    "    factuality = pipeline.verify3(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "aad50718219e084f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/168 [20:35<28:29:43, 617.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m search_word \u001B[38;5;241m=\u001B[39m entry\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocument_search_word\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     14\u001B[0m claim \u001B[38;5;241m=\u001B[39m entry\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconnected_claim\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m factuality \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverify3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclaim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menglish_word\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monly_intro\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit_facts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msearch_word\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msearch_word\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m factualities\u001B[38;5;241m.\u001B[39mappend(factuality)\n\u001B[1;32m     19\u001B[0m predicted, in_wiki \u001B[38;5;241m=\u001B[39m get_prediction(factuality)\n",
      "File \u001B[0;32m~/PycharmProjects/evaluating_factuality_word_definitions/pipeline/pipeline_old.py:83\u001B[0m, in \u001B[0;36mPipeline.verify3\u001B[0;34m(self, word, claim, fallback_word, split_facts, only_intro, atomic_claims, search_word)\u001B[0m\n\u001B[1;32m     81\u001B[0m factualities \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m atomic_claim \u001B[38;5;129;01min\u001B[39;00m atomic_claims:\n\u001B[0;32m---> 83\u001B[0m     factuality \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverify_claim\u001B[49m\u001B[43m(\u001B[49m\u001B[43matomic_claim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_ev_sents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     total_factuality \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m factuality \u001B[38;5;241m==\u001B[39m Fact\u001B[38;5;241m.\u001B[39mSUPPORTED \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     85\u001B[0m     factualities\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124matom\u001B[39m\u001B[38;5;124m'\u001B[39m: atomic_claim, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m: factuality\u001B[38;5;241m.\u001B[39mname})\n",
      "File \u001B[0;32m~/PycharmProjects/evaluating_factuality_word_definitions/pipeline/pipeline_old.py:212\u001B[0m, in \u001B[0;36mModelPipeline.verify_claim\u001B[0;34m(self, claim, sentences)\u001B[0m\n\u001B[1;32m    210\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_verification_model_input(claim, sentences)\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 212\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241m.\u001B[39mverification_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    213\u001B[0m     predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    215\u001B[0m     predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(predicted, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/PycharmProjects/evaluating_factuality_word_definitions/pipeline/pipeline_old.py:212\u001B[0m, in \u001B[0;36mModelPipeline.verify_claim\u001B[0;34m(self, claim, sentences)\u001B[0m\n\u001B[1;32m    210\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_verification_model_input(claim, sentences)\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 212\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241m.\u001B[39mverification_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    213\u001B[0m     predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    215\u001B[0m     predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(predicted, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional.app/Contents/plugins/python/helpers/pydev/pydevd.py:1185\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1182\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1184\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1185\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional.app/Contents/plugins/python/helpers/pydev/pydevd.py:1200\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1197\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1199\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1200\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:30:32.408823Z",
     "start_time": "2024-07-18T14:26:34.018675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_connected_base'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = entry.get('connected_claim')\n",
    "\n",
    "    factuality = pipeline_base.verify3(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "6edaaadd78ee0da0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [03:58<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6818    0.8696    0.7643        69\n",
      "           1     0.8235    0.6000    0.6942        70\n",
      "\n",
      "    accuracy                         0.7338       139\n",
      "   macro avg     0.7527    0.7348    0.7293       139\n",
      "weighted avg     0.7532    0.7338    0.7290       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## dissim facts",
   "id": "eab7afa761d1d1cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:13:45.201101Z",
     "start_time": "2024-07-18T15:08:58.460192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_dissim_finetuned'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = f'{search_word}: {entry.get(\"english_claim\", entry[\"claim\"])}'\n",
    "    atomic_facts = entry['atomic_facts']\n",
    "    atomic_facts = atomic_facts.split('--;--') if atomic_facts else []\n",
    "\n",
    "    factuality = pipeline.verify3(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word, atomic_claims=atomic_facts)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "7c2b50b0006e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:46<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6381    0.9710    0.7701        69\n",
      "           1     0.9412    0.4571    0.6154        70\n",
      "\n",
      "    accuracy                         0.7122       139\n",
      "   macro avg     0.7896    0.7141    0.6927       139\n",
      "weighted avg     0.7907    0.7122    0.6922       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:18:20.399713Z",
     "start_time": "2024-07-18T15:13:45.203939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_dissim_base'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = f'{search_word}: {entry.get(\"english_claim\", entry[\"claim\"])}'\n",
    "    atomic_facts = entry['atomic_facts']\n",
    "    atomic_facts = atomic_facts.split('--;--') if atomic_facts else []\n",
    "\n",
    "    factuality = pipeline_base.verify3(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word, atomic_claims=atomic_facts)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "1091fb2ac5bad150",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [04:35<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6465    0.9275    0.7619        69\n",
      "           1     0.8750    0.5000    0.6364        70\n",
      "\n",
      "    accuracy                         0.7122       139\n",
      "   macro avg     0.7607    0.7138    0.6991       139\n",
      "weighted avg     0.7616    0.7122    0.6987       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## factscore facts",
   "id": "1c1292678ba10fa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:23:49.063533Z",
     "start_time": "2024-07-18T15:18:20.402309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_factscore_finetuned'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = f'{search_word}: {entry.get(\"english_claim\", entry[\"claim\"])}'\n",
    "    atomic_facts = entry['factscore_facts']\n",
    "    atomic_facts = atomic_facts.split('--;--') if atomic_facts else []\n",
    "\n",
    "    factuality = pipeline_base.verify3(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word, atomic_claims=atomic_facts)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "1387e69b03579aa8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [05:28<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5877    0.9710    0.7322        69\n",
      "           1     0.9200    0.3286    0.4842        70\n",
      "\n",
      "    accuracy                         0.6475       139\n",
      "   macro avg     0.7539    0.6498    0.6082       139\n",
      "weighted avg     0.7551    0.6475    0.6073       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:29:16.547002Z",
     "start_time": "2024-07-18T15:23:49.067282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config import PROJECT_DIR\n",
    "\n",
    "identification = 'german_dpr_factscore_base'\n",
    "\n",
    "pr_labels = []\n",
    "gt_labels = []\n",
    "factualities = []\n",
    "not_in_wiki = 0\n",
    "lines = []\n",
    "for entry in tqdm(dataset):\n",
    "    word = entry.get('word')\n",
    "    english_word = entry.get('english_word', word)\n",
    "    search_word = entry.get('document_search_word')\n",
    "    claim = f'{search_word}: {entry.get(\"english_claim\", entry[\"claim\"])}'\n",
    "    atomic_facts = entry['factscore_facts']\n",
    "    atomic_facts = atomic_facts.split('--;--') if atomic_facts else []\n",
    "\n",
    "    factuality = pipeline_base.verify3(word, claim, english_word, only_intro=True, split_facts=False, search_word=search_word, atomic_claims=atomic_facts)\n",
    "    factualities.append(factuality)\n",
    "    \n",
    "    predicted, in_wiki = get_prediction(factuality)\n",
    "    \n",
    "    if in_wiki:\n",
    "        pr_labels.append(predicted.to_factuality())\n",
    "        gt_labels.append(Fact[entry['label']].to_factuality())\n",
    "    else:\n",
    "        not_in_wiki += 1\n",
    "    lines.append(build_output(entry, claim, predicted, factuality))\n",
    "\n",
    "print(f'Not in wiki {not_in_wiki}')\n",
    "print(classification_report(gt_labels, pr_labels, zero_division=0, digits=4))\n",
    "fh.write(PROJECT_DIR.joinpath(f'dataset/evaluation/{identification}_pipeline.jsonl'), lines)"
   ],
   "id": "b63b07f485dbb3e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [05:27<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in wiki 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5877    0.9710    0.7322        69\n",
      "           1     0.9200    0.3286    0.4842        70\n",
      "\n",
      "    accuracy                         0.6475       139\n",
      "   macro avg     0.7539    0.6498    0.6082       139\n",
      "weighted avg     0.7551    0.6475    0.6073       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:58:42.413079Z",
     "start_time": "2024-07-29T10:58:02.595281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pipeline.statement_verifier import ModelStatementVerifier\n",
    "from pipeline.evidence_selector import ModelEvidenceSelector\n",
    "from pipeline.translator import OpusMTTranslator\n",
    "from pipeline.sentence_connector import PhiSentenceConnector\n",
    "from pipeline.evidence_fetcher import WikipediaEvidenceFetcher\n",
    "from pipeline.pipeline2 import Pipeline\n",
    "\n",
    "translator = OpusMTTranslator()\n",
    "sent_connector = PhiSentenceConnector()\n",
    "claim_splitter = None\n",
    "evid_fetcher = WikipediaEvidenceFetcher()\n",
    "evid_selector = ModelEvidenceSelector()\n",
    "stm_verifier = ModelStatementVerifier()\n",
    "lang = 'de'\n",
    "\n",
    "pipeline = Pipeline(translator, sent_connector, claim_splitter, evid_fetcher, \n",
    "                    evid_selector, stm_verifier, lang)"
   ],
   "id": "62267080e641376c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "941305eca77243fd90c8fbadc750bd59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T10:58:45.683781Z",
     "start_time": "2024-07-29T10:58:42.416508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"lukasellinger/german_dpr_claim_verification_dissim-v1\", split='train')"
   ],
   "id": "268b8d4f4d97e734",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T11:02:40.853225Z",
     "start_time": "2024-07-29T10:58:45.686787Z"
    }
   },
   "cell_type": "code",
   "source": "outputs = pipeline.verify_test_dataset(dataset)",
   "id": "41e835aca171da1b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [03:55<00:00,  5.60s/it]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T11:02:40.861345Z",
     "start_time": "2024-07-29T11:02:40.857279Z"
    }
   },
   "cell_type": "code",
   "source": "print(outputs[1])",
   "id": "ba62d7e2bc47421",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7792    0.8696    0.8219        69\n",
      "           1     0.8548    0.7571    0.8030        70\n",
      "\n",
      "    accuracy                         0.8129       139\n",
      "   macro avg     0.8170    0.8134    0.8125       139\n",
      "weighted avg     0.8173    0.8129    0.8124       139\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from general_utils.reader import JSONLineReader\n",
    "\n",
    "JSONLineReader().write('test.jsonl', outputs[0])\n",
    "print(outputs[0])"
   ],
   "id": "661d3365d8fb9eac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def map_dataset(entry):\n",
    "    entry['DisSim_facts']\n",
    "    entry['FactScore_facts']\n",
    "\n",
    "dataset = dataset.map(map_dataset)"
   ],
   "id": "5a5366deb53fbf3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cbd69a29c7f50f22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
