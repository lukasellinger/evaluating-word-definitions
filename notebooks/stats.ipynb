{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:44:08.602478Z",
     "start_time": "2024-10-04T10:44:06.378797Z"
    }
   },
   "cell_type": "code",
   "source": "from datasets import load_dataset, concatenate_datasets",
   "id": "c8cc0a773a4c4645",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:21:07.675032Z",
     "start_time": "2024-09-10T10:21:03.709975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"lukasellinger/fever_evidence_selection-v1\")\n",
    "combined_dataset = concatenate_datasets([dataset['train'], dataset['dev'], dataset['test']])"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:21:39.261627Z",
     "start_time": "2024-09-10T10:21:39.252823Z"
    }
   },
   "cell_type": "code",
   "source": "combined_dataset[3]['evidence_lines']",
   "id": "4095a1b358e19b6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0;1;6;7;14;16;15'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:29:40.632252Z",
     "start_time": "2024-09-10T10:29:37.820186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count entries with more than 3 evidence lines\n",
    "count = 0\n",
    "for entry in combined_dataset:\n",
    "    evidences = entry['evidence_lines'].split(';')\n",
    "    min_evidence = 4\n",
    "    for evidence in evidences:\n",
    "        evidence_len = len(evidence.split(','))\n",
    "        if min_evidence > evidence_len:\n",
    "            min_evidence = evidence_len\n",
    "    if min_evidence > 3:\n",
    "        count += 1\n",
    "        \n",
    "print(f\"Number of entries with evidence lines > 3: {count}\")"
   ],
   "id": "78c24ac780f9679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with evidence lines > 3: 9\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T10:28:37.909719Z",
     "start_time": "2024-09-10T10:28:37.903597Z"
    }
   },
   "cell_type": "code",
   "source": "len(combined_dataset)",
   "id": "d0ad1128c93bba5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32900"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:48:26.512920Z",
     "start_time": "2024-10-04T10:48:10.785651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Datasets with language information\n",
    "datasets = {\n",
    "    'german_dpr-claim_verification': {\n",
    "        'dataset': load_dataset('lukasellinger/german_dpr-claim_verification', split='test'),\n",
    "        'lang': 'de'\n",
    "    },\n",
    "    'german_wiktionary-claim_verification-mini': {\n",
    "        'dataset': load_dataset('lukasellinger/german_wiktionary-claim_verification-mini', split='test'),\n",
    "        'lang': 'de'\n",
    "    },\n",
    "    'squad-claim_verification': {\n",
    "        'dataset': load_dataset('lukasellinger/squad-claim_verification', split='test'),\n",
    "        'lang': 'en'\n",
    "    },\n",
    "    'shroom-claim_verification': {\n",
    "        'dataset': load_dataset('lukasellinger/shroom-claim_verification', split='test'),\n",
    "        'lang': 'en'\n",
    "    }\n",
    "    # optional (contains 10k entries)\n",
    "    #'german_wiktionary-claim_verification-large': {\n",
    "    #    'dataset': load_dataset('lukasellinger/german_wiktionary-claim_verification-large', split='test'),\n",
    "    #    'lang': 'de'\n",
    "    #},\n",
    "    # outdated\n",
    "    #'german-claim_verification': {\n",
    "    #    'dataset': load_dataset('lukasellinger/german-claim_verification', split='test'),\n",
    "    #    'lang': 'de'\n",
    "    #},\n",
    "}\n",
    "\n",
    "fever = load_dataset('lukasellinger/filtered_fever-claim_verification')"
   ],
   "id": "4d170da2b9716f53",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T14:00:55.240257Z",
     "start_time": "2024-09-30T14:00:55.083384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    dataset = config['dataset']\n",
    "    data_dict = {}\n",
    "    \n",
    "    not_in_wiki = 0\n",
    "    avg_claim_count_wiki = {'DisSim_facts': 0,\n",
    "                            'Factscore_facts': 0,\n",
    "                            'T5SplitRephrase_facts': 0}\n",
    "    # Filter out entries not in the wiki and prepare the data_dict\n",
    "    for entry in dataset:\n",
    "        if entry['in_wiki'] == 'No':\n",
    "            not_in_wiki += 1\n",
    "        else:\n",
    "            for key in avg_claim_count_wiki.keys():\n",
    "                avg_claim_count_wiki[key] += len(entry[key].split('--;--'))        \n",
    "    for key, value in avg_claim_count_wiki.items():\n",
    "        avg_claim_count_wiki[key] = round(value / (len(dataset) - not_in_wiki), 2)\n",
    "    print(f'{dataset_name}: {1 - round(not_in_wiki / len(dataset), 4)}, {not_in_wiki}')\n",
    "    print(avg_claim_count_wiki)\n",
    "    print('-----------------')"
   ],
   "id": "77ecf18649b99ea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: 0.8274, 29\n",
      "{'DisSim_facts': 1.87, 'Factscore_facts': 3.56, 'T5SplitRephrase_facts': 1.47}\n",
      "-----------------\n",
      "german_wiktionary-claim_verification-mini: 0.8, 40\n",
      "{'DisSim_facts': 1.7, 'Factscore_facts': 3.76, 'T5SplitRephrase_facts': 1.62}\n",
      "-----------------\n",
      "squad-claim_verification: 0.7975, 32\n",
      "{'DisSim_facts': 1.12, 'Factscore_facts': 2.39, 'T5SplitRephrase_facts': 1.06}\n",
      "-----------------\n",
      "shroom-claim_verification: 0.9627, 21\n",
      "{'DisSim_facts': 1.27, 'Factscore_facts': 2.73, 'T5SplitRephrase_facts': 1.22}\n",
      "-----------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T03:50:42.864978Z",
     "start_time": "2024-10-01T03:50:42.855498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dpr = 82.01\n",
    "wiki = 70.63\n",
    "squad = 87.30\n",
    "shroom = 69.37\n",
    "\n",
    "result = (136 * dpr + 160 * wiki + 126 * squad + 542 * shroom) / 967\n",
    "print(result)"
   ],
   "id": "256df6e062b656ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.47724922440538\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:46:16.481589Z",
     "start_time": "2024-10-04T10:46:16.457701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, config in datasets.items():\n",
    "    dataset = config['dataset']\n",
    "    \n",
    "    def claim_word_length(example):\n",
    "        # Split the claim into words and count the number of words\n",
    "        return {\"word_length\": len(example['claim'].split())}\n",
    "    \n",
    "    # Apply the function to the entire dataset using map\n",
    "    dataset_with_lengths = dataset.map(claim_word_length)\n",
    "    \n",
    "    # Now compute the average word length\n",
    "    avg_word_length = sum(dataset_with_lengths['word_length']) / len(dataset_with_lengths)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"{dataset_name}: Avg Claim Length: {avg_word_length:.2f}\")\n"
   ],
   "id": "92d5259ab8ae0d6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_dpr-claim_verification: Avg Claim Length: 11.93\n",
      "german_wiktionary-claim_verification-mini: Avg Claim Length: 11.19\n",
      "squad-claim_verification: Avg Claim Length: 3.32\n",
      "shroom-claim_verification: Avg Claim Length: 6.48\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:48:46.847503Z",
     "start_time": "2024-10-04T10:48:46.802766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name, dataset in fever.items():    \n",
    "    def claim_word_length(example):\n",
    "        # Split the claim into words and count the number of words\n",
    "        return {\"word_length\": len(example['claim'].split())}\n",
    "    \n",
    "    # Apply the function to the entire dataset using map\n",
    "    dataset_with_lengths = dataset.map(claim_word_length)\n",
    "    \n",
    "    # Now compute the average word length\n",
    "    avg_word_length = sum(dataset_with_lengths['word_length']) / len(dataset_with_lengths)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"{dataset_name}: Avg Claim Length: {avg_word_length:.2f}\")"
   ],
   "id": "75b83c5c7f5009f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Avg Claim Length: 7.23\n",
      "dev: Avg Claim Length: 7.25\n",
      "test: Avg Claim Length: 7.35\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af81dcac58c64a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
